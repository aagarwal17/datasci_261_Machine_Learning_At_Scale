{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e05b5bb-0ee3-4f28-bf8e-fa81c3b63445",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a53be288-2f6c-47fc-855e-789244579c14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, log, lit\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.sql.functions import skewness\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d09bbc83-25bf-4321-ba85-3b9d68524f82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Prepareation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7464a26-fae2-4d4f-8f14-c6ebca55e3b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa40088-0873-448f-a5c8-f726a366f5e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9009126"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_undersampled_raw = spark.read.parquet(\"dbfs:/student-groups/Group_4_4/cp6_train_2015_2017_undersampled_0_5_ratio.parquet\")\n",
    "df_val_2018_raw = spark.read.parquet(\"dbfs:/student-groups/Group_4_4/cp6_val_2018_refined.parquet\")\n",
    "df_test_2019_raw = spark.read.parquet(\"dbfs:/student-groups/Group_4_4/cp6_test_2019_refined.parquet\")\n",
    "\n",
    "df_train_undersampled_raw = df_train_undersampled_raw.cache()\n",
    "df_train_undersampled_raw.count()  # force materialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f379c64b-9dd1-4e82-a3f2-41c1438a602c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: 113\n"
     ]
    }
   ],
   "source": [
    "print(f\"Columns: {len(df_train_undersampled_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f2fc49a-a8a0-4510-85db-663397c6467e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['DEST',\n",
       " 'ORIGIN',\n",
       " 'OP_UNIQUE_CARRIER',\n",
       " 'FL_DATE',\n",
       " 'prediction_utc',\n",
       " 'origin_obs_utc',\n",
       " 'asof_minutes',\n",
       " 'DAY_OF_MONTH',\n",
       " 'DAY_OF_WEEK',\n",
       " 'OP_CARRIER_FL_NUM',\n",
       " 'CRS_ARR_TIME',\n",
       " 'ORIGIN_AIRPORT_ID',\n",
       " 'ORIGIN_STATE_ABR',\n",
       " 'DEST_AIRPORT_ID',\n",
       " 'DEST_STATE_ABR',\n",
       " 'HourlyDryBulbTemperature',\n",
       " 'HourlyDewPointTemperature',\n",
       " 'HourlyWindDirection',\n",
       " 'HourlyWindGustSpeed',\n",
       " 'HourlyVisibility',\n",
       " 'HourlyRelativeHumidity',\n",
       " 'HourlyStationPressure',\n",
       " 'HourlyAltimeterSetting',\n",
       " 'origin_airport_lat',\n",
       " 'origin_airport_lon',\n",
       " 'dest_airport_lat',\n",
       " 'dest_airport_lon',\n",
       " 'origin_station_dis',\n",
       " 'dest_station_dis',\n",
       " 'origin_type',\n",
       " 'DEP_DEL15',\n",
       " 'DEP_DELAY',\n",
       " 'season',\n",
       " 'rolling_origin_num_delays_24h',\n",
       " 'dep_delay15_24h_rolling_avg_by_origin_dayofweek',\n",
       " 'dep_delay15_24h_rolling_avg_by_origin_log',\n",
       " 'dep_delay15_24h_rolling_avg_by_origin_carrier_log',\n",
       " 'dep_delay15_24h_rolling_avg_by_origin_dayofweek_log',\n",
       " 'is_superbowl_week',\n",
       " 'is_major_event',\n",
       " 'distance_very_long',\n",
       " 'weather_condition_category',\n",
       " 'is_airport_maintenance',\n",
       " 'is_natural_disaster',\n",
       " 'airline_reputation_score',\n",
       " 'airline_reputation_category',\n",
       " 'airport_traffic_density',\n",
       " 'carrier_flight_count',\n",
       " 'log_distance',\n",
       " 'prev_flight_dep_del15',\n",
       " 'prev_flight_crs_elapsed_time',\n",
       " 'hours_since_prev_flight',\n",
       " 'turnaround_category',\n",
       " 'num_airport_wide_delays',\n",
       " 'oncoming_flights',\n",
       " 'day_hour_interaction',\n",
       " 'prior_day_delay_rate',\n",
       " 'prior_flights_today',\n",
       " 'same_day_prior_delay_percentage',\n",
       " 'time_based_congestion_ratio',\n",
       " 'sky_condition_parsed',\n",
       " 'temp_anomaly',\n",
       " 'dep_time_sin',\n",
       " 'dep_time_cos',\n",
       " 'arr_time_sin',\n",
       " 'arr_time_cos',\n",
       " 'day_of_week_sin',\n",
       " 'day_of_week_cos',\n",
       " 'month_sin',\n",
       " 'origin_degree_centrality',\n",
       " 'dest_betweenness',\n",
       " 'dest_delay_rate_today',\n",
       " 'delay_propagation_score',\n",
       " 'network_delay_cascade',\n",
       " 'days_since_epoch',\n",
       " 'origin_1yr_delay_rate',\n",
       " 'dest_1yr_delay_rate',\n",
       " 'rolling_30day_volume',\n",
       " 'days_since_last_delay_route',\n",
       " 'days_since_carrier_last_delay_at_origin',\n",
       " 'route_delays_30d',\n",
       " 'route_delay_rate_30d',\n",
       " 'carrier_delays_at_origin_30d',\n",
       " 'peak_hour_x_traffic',\n",
       " 'weekend_x_route_volume',\n",
       " 'weather_x_airport_delays',\n",
       " 'temp_x_holiday',\n",
       " 'route_delay_rate_x_peak_hour',\n",
       " 'carrier_encoded_x_hour',\n",
       " 'origin_encoded_x_weather',\n",
       " 'origin_encoded_x_visibility',\n",
       " 'origin_encoded_x_precipitation',\n",
       " 'origin_encoded_x_wind',\n",
       " 'origin_x_dest_encoded',\n",
       " 'carrier_x_origin_encoded',\n",
       " 'carrier_x_dest_encoded',\n",
       " 'rf_prob_delay',\n",
       " 'rf_prob_delay_binned',\n",
       " 'dep_delay15_24h_rolling_avg_by_origin_carrier_weighted',\n",
       " 'dep_delay15_24h_rolling_avg_by_origin_weighted',\n",
       " 'DEST_indexed',\n",
       " 'ORIGIN_indexed',\n",
       " 'OP_UNIQUE_CARRIER_indexed',\n",
       " 'ORIGIN_STATE_ABR_indexed',\n",
       " 'DEST_STATE_ABR_indexed',\n",
       " 'origin_type_indexed',\n",
       " 'season_indexed',\n",
       " 'weather_condition_category_indexed',\n",
       " 'airline_reputation_category_indexed',\n",
       " 'turnaround_category_indexed',\n",
       " 'day_hour_interaction_indexed',\n",
       " 'sky_condition_parsed_indexed',\n",
       " 'YEAR']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_undersampled_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bc262ea-f7b9-4fa8-9f8c-91778d292bae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Festure Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3528aa86-cfd3-4782-a3c5-6f9a1719beeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Identify Column Category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af5927dc-377c-4b5d-86e7-bd5ea84744fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Label Column\n",
    "# ============================================================\n",
    "# DEP_DEL15 is the target variable indicating whether a flight\n",
    "# departed with a delay of 15 minutes or more (1 = delayed, 0 = on time).\n",
    "label_col = \"DEP_DEL15\"\n",
    "\n",
    "# Identify string columns (excluding the label)\n",
    "string_cols = [c for c, t in df_train_undersampled_raw.dtypes if t == \"string\" and c != label_col]\n",
    "\n",
    "# ============================================================\n",
    "# Leakage Columns\n",
    "# ============================================================\n",
    "# These columns must be removed because they reveal information\n",
    "# that would NOT be available at prediction time, or they encode\n",
    "# outcomes of the flight. Including them would lead to severe\n",
    "# data leakage and unrealistic model performance.\n",
    "leakage_cols = [\n",
    "    # --------------------------------------------------------\n",
    "    # Direct outcome information — known only after the flight\n",
    "    # --------------------------------------------------------\n",
    "    \"CANCELLED\",                # Cancellation outcome\n",
    "    \"CANCELLATION_CODE\",        # Reason for cancellation\n",
    "    \"DIVERTED\",                 # Diversion outcome\n",
    "    \"DEP_DELAY\",           # true departure delay (leakage)\n",
    "    \"rf_prob_delay\",       # RF model prediction\n",
    "    \"rf_prob_delay_binned\", # binned RF prediction\n",
    "\n",
    "    # Arrival-related data (results of the flight)\n",
    "    \"ARR_DEL15_removed\",\n",
    "    \"ARR_TIME_removed\",\n",
    "    \"ARR_DELAY_removed\",\n",
    "    \"TAXI_IN_removed\",\n",
    "    \"AIR_TIME_removed\",\n",
    "    \"WHEELS_OFF_removed\",\n",
    "    \"WHEELS_ON_removed\",\n",
    "    \"ACTUAL_ELAPSED_TIME_removed\",\n",
    "\n",
    "    # Delay reason codes — these explicitly encode true causes\n",
    "    # and are not available prior to departure\n",
    "    \"CARRIER_DELAY_removed\",\n",
    "    \"WEATHER_DELAY_removed\",\n",
    "    \"NAS_DELAY_removed\",\n",
    "    \"SECURITY_DELAY_removed\",\n",
    "    \"LATE_AIRCRAFT_DELAY_removed\",\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Ground-truth weather measurements (removed versions)\n",
    "    # These represent real observed values rather than forecasted\n",
    "    # or lagged values, so they cannot be used for prediction.\n",
    "    # --------------------------------------------------------\n",
    "    \"HourlyDryBulbTemperature_removed\",\n",
    "    \"HourlyWetBulbTemperature_removed\",\n",
    "    \"HourlyStationPressure_removed\",\n",
    "    \"HourlySeaLevelPressure_removed\",\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Geographic / distance fields duplicated with future info\n",
    "    # The \"_removed\" versions often reflect information derived\n",
    "    # from ground truth sources and should not be used.\n",
    "    # --------------------------------------------------------\n",
    "    \"origin_station_lat_removed\",\n",
    "    \"origin_station_lon_removed\",\n",
    "    \"origin_airport_lat_removed\",\n",
    "    \"origin_airport_lon_removed\",\n",
    "    \"dest_station_lat_removed\",\n",
    "    \"dest_station_lon_removed\",\n",
    "    \"dest_airport_lat_removed\",\n",
    "    \"dest_airport_lon_removed\",\n",
    "    \"origin_station_dis_removed\",\n",
    "    \"dest_station_dis_removed\",\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Historical features where the removed versions may contain\n",
    "    # lookahead information or future aggregates.\n",
    "    # --------------------------------------------------------\n",
    "    \"rolling_origin_num_flights_24h_removed\",\n",
    "    \"rolling_origin_delay_ratio_24h_removed\",\n",
    "    \"rolling_origin_stddev_dep_delay_24h_removed\",\n",
    "    \"total_flights_per_origin_day_removed\",\n",
    "    \"prior_flights_today_removed\",\n",
    "    \"prior_delays_today_removed\",\n",
    "    \"same_day_prior_delay_percentage_removed\",\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Distance / route fields duplicated in a removed form.\n",
    "    # Clean versions (e.g., log_distance) should be used instead.\n",
    "    # --------------------------------------------------------\n",
    "    \"DISTANCE_removed\",\n",
    "    \"DISTANCE_GROUP_removed\",\n",
    "    \"distance_short_removed\",\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Miscellaneous fields removed for leakage or redundancy\n",
    "    # --------------------------------------------------------\n",
    "    \"flight_id_removed\",\n",
    "    \"HourlySkyConditions_removed\",\n",
    "    \"HourlyPresentWeatherType_removed\",\n",
    "    \"temp_humidity_interaction_removed\",\n",
    "    \"precip_anomaly_removed\",\n",
    "    \"extreme_precipitation_removed\",\n",
    "    \"extreme_weather_score_removed\",\n",
    "    \"num_airport_wide_cancellations_removed\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e7bdd50-0baa-440b-accf-d51ec24eb41d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### High Cardinality Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccead216-5041-46e1-b1c8-53a7f084de5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGIN_indexed                            328\nDEST_indexed                              320\nday_hour_interaction_indexed              158\nORIGIN_STATE_ABR_indexed                  50\nDEST_STATE_ABR_indexed                    50\nOP_UNIQUE_CARRIER_indexed                 14\nsky_condition_parsed_indexed              6\nairline_reputation_category_indexed       5\nseason_indexed                            4\nturnaround_category_indexed               4\norigin_type_indexed                       3\nweather_condition_category_indexed        3\nHigh-cardinality categorical columns (to drop):\n  DEST_indexed                             → 320 distinct values\n  ORIGIN_indexed                           → 328 distinct values\n  day_hour_interaction_indexed             → 158 distinct values\n"
     ]
    }
   ],
   "source": [
    "# Compute cardinality for each categorical column\n",
    "indexed_cols = [c for c in df_train_undersampled_raw.columns if c.endswith(\"_indexed\")]\n",
    "\n",
    "cardinality_exprs = [\n",
    "    approx_count_distinct(c).alias(c)\n",
    "    for c in indexed_cols\n",
    "]\n",
    "cardinality_row = df_train_undersampled_raw.select(cardinality_exprs).first()\n",
    "cardinality_dict  = {c: cardinality_row[c] for c in indexed_cols}\n",
    "\n",
    "# Sort by cardinality (high → low)\n",
    "sorted_cardinality = sorted(cardinality_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for col, cnt in sorted_cardinality:\n",
    "    print(f\"{col:40}  {cnt}\")\n",
    "\n",
    "THRESHOLD = 100   \n",
    "\n",
    "drop_high_card_cols = [c for c, cnt in cardinality_dict.items() if cnt > THRESHOLD]\n",
    "print(\"High-cardinality categorical columns (to drop):\")\n",
    "for c in drop_high_card_cols:\n",
    "    print(f\"  {c:40s} → {cardinality_dict[c]} distinct values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd9e3096-be72-49d8-9d07-330f751a4a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cbbb4ce-9103-4d80-bdba-2fff556aa88c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 113\nTest rows : 113\nTrain column cleaned: 92\nTest column cleaned: 92\n"
     ]
    }
   ],
   "source": [
    "print(\"Train rows:\", len(df_val_2018_raw.columns))\n",
    "print(\"Test rows :\", len(df_test_2019_raw.columns))\n",
    "\n",
    "df_train_undersampled =  (\n",
    "    df_train_undersampled_raw\n",
    "      .drop(*leakage_cols)\n",
    "      .drop(*string_cols)\n",
    "      .drop(*drop_high_card_cols)\n",
    "      .drop(\"FL_DATE\", \"prediction_utc\", \"origin_obs_utc\")\n",
    ")\n",
    "\n",
    "df_val_2018 =  (\n",
    "    df_val_2018_raw\n",
    "      .drop(*leakage_cols)\n",
    "      .drop(*string_cols)\n",
    "      .drop(*drop_high_card_cols)\n",
    "      .drop(\"FL_DATE\", \"prediction_utc\", \"origin_obs_utc\")\n",
    ")\n",
    "\n",
    "df_test_2019 =  (\n",
    "    df_test_2019_raw\n",
    "      .drop(*leakage_cols)\n",
    "      .drop(*string_cols)\n",
    "      .drop(*drop_high_card_cols)\n",
    "      .drop(\"FL_DATE\", \"prediction_utc\", \"origin_obs_utc\")\n",
    ")\n",
    "\n",
    "print(\"Train column cleaned:\",len(df_val_2018.columns))\n",
    "print(\"Test column cleaned:\", len(df_test_2019.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc592f40-4d91-48f2-8d68-f4ae8c2795d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df_train_undersampled.columns if c != label_col and  c not in drop_high_card_cols]\n",
    "\n",
    "df_train_undersampled = df_train_undersampled.na.drop(subset=feature_cols)\n",
    "df_val_2018   = df_val_2018.na.drop(subset=feature_cols)\n",
    "df_test_2019  = df_test_2019.na.drop(subset=feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f9eb159-27c3-40df-8a58-2dc1348f6cb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Define Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ef0014b-54a9-446f-8b79-42e2f83bbf89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "label_col = \"DEP_DEL15\"\n",
    "\n",
    "# ============================================================\n",
    "# 1. Feature columns & assembler\n",
    "# ============================================================\n",
    "# Use all non-label columns as features\n",
    "feature_cols = [c for c in df_train_undersampled.columns if c != label_col and  c not in drop_high_card_cols]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Evaluators for AUC-PR & AUC-ROC\n",
    "# ============================================================\n",
    "evaluator_pr = BinaryClassificationEvaluator(\n",
    "    labelCol=label_col,\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderPR\"\n",
    ")\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(\n",
    "    labelCol=label_col,\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3. F_beta (here F0.5) helper\n",
    "# ============================================================\n",
    "def compute_fbeta(df, label_col, prediction_col=\"prediction\", beta=0.5):\n",
    "    \"\"\"\n",
    "    Compute F_beta, precision, and recall from a DataFrame\n",
    "    that already has hard predictions in `prediction_col`.\n",
    "    \"\"\"\n",
    "    agg = (\n",
    "        df\n",
    "        .select(\n",
    "            F.col(label_col).cast(\"int\").alias(\"y\"),\n",
    "            F.col(prediction_col).cast(\"int\").alias(\"yhat\")\n",
    "        )\n",
    "        .selectExpr(\n",
    "            \"sum(CASE WHEN y = 1 AND yhat = 1 THEN 1 ELSE 0 END) AS tp\",\n",
    "            \"sum(CASE WHEN y = 0 AND yhat = 1 THEN 1 ELSE 0 END) AS fp\",\n",
    "            \"sum(CASE WHEN y = 1 AND yhat = 0 THEN 1 ELSE 0 END) AS fn\"\n",
    "        )\n",
    "        .collect()[0]\n",
    "    )\n",
    "\n",
    "    tp = agg[\"tp\"]\n",
    "    fp = agg[\"fp\"]\n",
    "    fn = agg[\"fn\"]\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "    beta2 = beta ** 2\n",
    "    denom = beta2 * precision + recall\n",
    "\n",
    "    if denom == 0:\n",
    "        fbeta = 0.0\n",
    "    else:\n",
    "        fbeta = (1 + beta2) * precision * recall / denom\n",
    "\n",
    "    return fbeta, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06e1d4fe-2488-4c13-9f60-de65043f4544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#  GB with Early Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5b0c071-9c44-432e-b7e8-956fc6e2c793",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**MODELING - GBDT & RF IMPROVEMENTS**\n",
    "- • Implement early stopping for GradientBoostedTrees using validation set\n",
    "- • Grid search over max_depth, n_trees, learning_rate for GBDT\n",
    "- • Tune Random Forest with different tree counts and max_depth values\n",
    "- • Decide early stopping criteria: quit at first poor performance vs persevere for more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cb13f52-cd43-4f24-8de7-a579629a2251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define GB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "442b2d81-22a1-4d35-bb85-6916b9f7a196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 4. Train + evaluate one GBT config\n",
    "# ============================================================\n",
    "def train_gbt_and_eval(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    assembler,\n",
    "    label_col,\n",
    "    num_iters,\n",
    "    max_depth=5,\n",
    "    step_size=0.1,\n",
    "    subsampling_rate=0.8,\n",
    "    seed=42\n",
    "):\n",
    "    gbt = GBTClassifier(\n",
    "        labelCol=label_col,\n",
    "        featuresCol=\"features\",\n",
    "        maxIter=num_iters,\n",
    "        maxDepth=max_depth,\n",
    "        maxBins=64,\n",
    "        stepSize=step_size,\n",
    "        subsamplingRate=subsampling_rate,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(stages=[assembler, gbt])\n",
    "\n",
    "    model = pipeline.fit(train_df)\n",
    "\n",
    "    val_pred = model.transform(val_df)\n",
    "\n",
    "    auc_pr  = evaluator_pr.evaluate(val_pred)\n",
    "    auc_roc = evaluator_roc.evaluate(val_pred)\n",
    "    f05, prec, rec = compute_fbeta(val_pred, label_col, prediction_col=\"prediction\")\n",
    "\n",
    "    metrics = {\n",
    "        \"auc_pr\": auc_pr,\n",
    "        \"auc_roc\": auc_roc,\n",
    "        \"f0_5\": f05,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "    }\n",
    "\n",
    "    return model, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a086851-c16b-480a-8564-ea5d83603aa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define Early Stop for GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "191cfe03-160e-4434-94ec-4476f0a87979",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_iter_grid = [ 70, 80,90]\n",
    "#num_iter_grid = [20]\n",
    "\n",
    "def run_early_stop_for_one_config(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    assembler,\n",
    "    label_col,\n",
    "    max_depth,\n",
    "    step_size,\n",
    "    subsampling_rate,\n",
    "    num_iter_grid=num_iter_grid,\n",
    "    patience=2,\n",
    "    min_delta=0.001\n",
    "):\n",
    "    best_model = None\n",
    "    best_num_iter = None\n",
    "    best_metrics = None\n",
    "    best_score = float(\"-inf\")\n",
    "    no_improve_rounds = 0\n",
    "\n",
    "    for num_iters in num_iter_grid:\n",
    "        model, metrics = train_gbt_and_eval(\n",
    "            train_df=train_df,\n",
    "            val_df=val_df,\n",
    "            assembler=assembler,\n",
    "            label_col=label_col,\n",
    "            num_iters=num_iters,\n",
    "            max_depth=max_depth,\n",
    "            step_size=step_size,\n",
    "            subsampling_rate=subsampling_rate\n",
    "        )\n",
    "\n",
    "        auc_pr  = metrics[\"auc_pr\"]\n",
    "        auc_roc = metrics[\"auc_roc\"]\n",
    "        f05     = metrics[\"f0_5\"]\n",
    "\n",
    "        print(\n",
    "            f\"[config: depth={max_depth}, step={step_size}, subs={subsampling_rate}] \"\n",
    "            f\"numIters={num_iters:3d} | \"\n",
    "            f\"val AUC-PR={auc_pr:.4f}, AUC-ROC={auc_roc:.4f}, F0.5={f05:.4f}\"\n",
    "        )\n",
    "\n",
    "        if auc_pr > best_score + min_delta:\n",
    "            best_score = auc_pr\n",
    "            best_model = model\n",
    "            best_num_iter = num_iters\n",
    "            best_metrics = metrics\n",
    "            no_improve_rounds = 0\n",
    "        else:\n",
    "            no_improve_rounds += 1\n",
    "\n",
    "        if no_improve_rounds >= patience:\n",
    "            print(\n",
    "                f\"Early stopping triggered for this config at numIters={num_iters}, \"\n",
    "                f\"best numIters so far={best_num_iter}\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "    print(\n",
    "        f\"--> Best for this config: depth={max_depth}, step={step_size}, subs={subsampling_rate}, \"\n",
    "        f\"numIters={best_num_iter}, AUC-PR={best_metrics['auc_pr']:.4f}, \"\n",
    "        f\"AUC-ROC={best_metrics['auc_roc']:.4f}, F0.5={best_metrics['f0_5']:.4f}\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"max_depth\": max_depth,\n",
    "        \"step_size\": step_size,\n",
    "        \"subsampling_rate\": subsampling_rate,\n",
    "        \"best_num_iters\": best_num_iter,\n",
    "        \"auc_pr\": best_metrics[\"auc_pr\"],\n",
    "        \"auc_roc\": best_metrics[\"auc_roc\"],\n",
    "        \"f0_5\": best_metrics[\"f0_5\"],\n",
    "        \"model\": best_model,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1f53f85-6c2f-468a-9f90-279b039bde0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Grid Search GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d97b623d-ea37-41e1-9152-87e03d9af004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n==============================\nTesting config: {'max_depth': 3, 'step_size': 0.1, 'subsampling_rate': 0.8}\n==============================\n[config: depth=3, step=0.1, subs=0.8] numIters= 70 | val AUC-PR=0.6668, AUC-ROC=0.8761, F0.5=0.6259\n[config: depth=3, step=0.1, subs=0.8] numIters= 80 | val AUC-PR=0.6706, AUC-ROC=0.8779, F0.5=0.6275\n[config: depth=3, step=0.1, subs=0.8] numIters= 90 | val AUC-PR=0.6771, AUC-ROC=0.8802, F0.5=0.6295\n--> Best for this config: depth=3, step=0.1, subs=0.8, numIters=90, AUC-PR=0.6771, AUC-ROC=0.8802, F0.5=0.6295\n\n==============================\nTesting config: {'max_depth': 5, 'step_size': 0.1, 'subsampling_rate': 0.8}\n==============================\n[config: depth=5, step=0.1, subs=0.8] numIters= 70 | val AUC-PR=0.7128, AUC-ROC=0.8916, F0.5=0.6384\n[config: depth=5, step=0.1, subs=0.8] numIters= 80 | val AUC-PR=0.7162, AUC-ROC=0.8933, F0.5=0.6400\n[config: depth=5, step=0.1, subs=0.8] numIters= 90 | val AUC-PR=0.7191, AUC-ROC=0.8945, F0.5=0.6415\n--> Best for this config: depth=5, step=0.1, subs=0.8, numIters=90, AUC-PR=0.7191, AUC-ROC=0.8945, F0.5=0.6415\n\n==============================\nTesting config: {'max_depth': 5, 'step_size': 0.05, 'subsampling_rate': 0.8}\n==============================\n[config: depth=5, step=0.05, subs=0.8] numIters= 70 | val AUC-PR=0.6923, AUC-ROC=0.8825, F0.5=0.6300\n[config: depth=5, step=0.05, subs=0.8] numIters= 80 | val AUC-PR=0.6955, AUC-ROC=0.8842, F0.5=0.6310\n[config: depth=5, step=0.05, subs=0.8] numIters= 90 | val AUC-PR=0.6993, AUC-ROC=0.8859, F0.5=0.6329\n--> Best for this config: depth=5, step=0.05, subs=0.8, numIters=90, AUC-PR=0.6993, AUC-ROC=0.8859, F0.5=0.6329\n"
     ]
    }
   ],
   "source": [
    "configs = [\n",
    "    {\"max_depth\": 3, \"step_size\": 0.1, \"subsampling_rate\": 0.8},\n",
    "    {\"max_depth\": 5, \"step_size\": 0.1, \"subsampling_rate\": 0.8},\n",
    "    {\"max_depth\": 5, \"step_size\": 0.05, \"subsampling_rate\": 0.8},\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for cfg in configs:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"Testing config: {cfg}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    res = run_early_stop_for_one_config(\n",
    "        train_df=df_train_undersampled,\n",
    "        val_df=df_val_2018,\n",
    "        assembler=assembler,\n",
    "        label_col=label_col,\n",
    "        max_depth=cfg[\"max_depth\"],\n",
    "        step_size=cfg[\"step_size\"],\n",
    "        subsampling_rate=cfg[\"subsampling_rate\"],\n",
    "    )\n",
    "\n",
    "    all_results.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c09acf-11b3-4baf-8d26-01b4d7c74814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n====== Best overall GBT config on validation set ======\nmaxDepth=5, stepSize=0.1, subsamplingRate=0.8, numIters=90, AUC-PR=0.7191, AUC-ROC=0.8945, F0.5=0.6415\n"
     ]
    }
   ],
   "source": [
    "best_overall_gb = max(all_results, key=lambda x: x[\"auc_pr\"])\n",
    "\n",
    "print(\"\\n====== Best overall GBT config on validation set ======\")\n",
    "print(\n",
    "    f\"maxDepth={best_overall_gb['max_depth']}, \"\n",
    "    f\"stepSize={best_overall_gb['step_size']}, \"\n",
    "    f\"subsamplingRate={best_overall_gb['subsampling_rate']}, \"\n",
    "    f\"numIters={best_overall_gb['best_num_iters']}, \"\n",
    "    f\"AUC-PR={best_overall_gb['auc_pr']:.4f}, \"\n",
    "    f\"AUC-ROC={best_overall_gb['auc_roc']:.4f}, \"\n",
    "    f\"F0.5={best_overall_gb['f0_5']:.4f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "baf41cd0-681d-4a7c-b5e7-88fc48acb44a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train Final GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8ad93f5-5005-47f5-9439-0efc0fe87c12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_gbt = GBTClassifier(\n",
    "    labelCol=label_col,\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=best_overall_gb[\"best_num_iters\"],\n",
    "    maxDepth=best_overall_gb[\"max_depth\"],\n",
    "    stepSize=best_overall_gb[\"step_size\"],\n",
    "    subsamplingRate=best_overall_gb[\"subsampling_rate\"],\n",
    "    maxBins=64,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "final_pipeline_gbt = Pipeline(stages=[assembler, final_gbt])\n",
    "\n",
    "final_model_gbt = final_pipeline_gbt.fit(df_train_undersampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f300feef-a5b9-4a8b-86f8-d37df6e75a06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test Final GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d9b42ec-9897-46ba-992c-9ef82e1eeeba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Final Test Metrics =====\nAUC-PR  = 0.6832\nAUC-ROC = 0.8818\nF0.5    = 0.6366\nPrecision = 0.6407\nRecall    = 0.6206\n"
     ]
    }
   ],
   "source": [
    "test_pred_gbt = final_model_gbt.transform(df_test_2019)\n",
    "\n",
    "test_auc_pr_gbt  = evaluator_pr.evaluate(test_pred_gbt)\n",
    "test_auc_roc_gbt = evaluator_roc.evaluate(test_pred_gbt)\n",
    "\n",
    "test_f05_gbt, test_prec_gbt, test_rec_gbt = compute_fbeta(\n",
    "    test_pred_gbt,\n",
    "    label_col,\n",
    "    prediction_col=\"prediction\"\n",
    ")\n",
    "\n",
    "print(\"===== Final Test Metrics =====\")\n",
    "print(f\"AUC-PR  = {test_auc_pr_gbt:.4f}\")\n",
    "print(f\"AUC-ROC = {test_auc_roc_gbt:.4f}\")\n",
    "print(f\"F0.5    = {test_f05_gbt:.4f}\")\n",
    "print(f\"Precision = {test_prec_gbt:.4f}\")\n",
    "print(f\"Recall    = {test_rec_gbt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d62525b-0f3f-4285-aa3e-44fdd131ef0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# RF with Early Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7b29f44-7e46-4d8e-ab1b-e5bbeb8fa3ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02f01923-efcc-4444-aab7-9dce2e12440c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "def train_rf_and_eval(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    assembler,\n",
    "    label_col,\n",
    "    num_trees,\n",
    "    max_depth,\n",
    "    seed=42\n",
    "):\n",
    "    rf = RandomForestClassifier(\n",
    "        labelCol=label_col,\n",
    "        featuresCol=\"features\",\n",
    "        numTrees=num_trees,\n",
    "        maxDepth=max_depth,\n",
    "        maxBins=64,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(stages=[assembler, rf])\n",
    "    model = pipeline.fit(train_df)\n",
    "\n",
    "    val_pred = model.transform(val_df)\n",
    "\n",
    "    auc_pr  = evaluator_pr.evaluate(val_pred)\n",
    "    auc_roc = evaluator_roc.evaluate(val_pred)\n",
    "    f05, prec, rec = compute_fbeta(val_pred, label_col, prediction_col=\"prediction\")\n",
    "\n",
    "    metrics = {\n",
    "        \"auc_pr\": auc_pr,\n",
    "        \"auc_roc\": auc_roc,\n",
    "        \"f0_5\": f05,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "    }\n",
    "\n",
    "    return model, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cffa3c3-84ab-4093-b967-6bfde39326bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Grid Search RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49a3c7a9-7b50-4b9b-8953-b8d051553e54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] depth=5, numTrees=10 | val AUC-PR=0.5722, AUC-ROC=0.8318, F0.5=0.5747\n[RF] depth=5, numTrees=15 | val AUC-PR=0.5642, AUC-ROC=0.8299, F0.5=0.5557\n  -> early stop on numTrees for depth=5\n[RF] depth=8, numTrees=10 | val AUC-PR=0.6113, AUC-ROC=0.8485, F0.5=0.6036\n[RF] depth=8, numTrees=15 | val AUC-PR=0.6075, AUC-ROC=0.8480, F0.5=0.6026\n  -> early stop on numTrees for depth=8\n[RF] depth=10, numTrees=10 | val AUC-PR=0.6340, AUC-ROC=0.8576, F0.5=0.6142\n[RF] depth=10, numTrees=15 | val AUC-PR=0.6318, AUC-ROC=0.8582, F0.5=0.6211\n  -> early stop on numTrees for depth=10\n[RF] depth=15, numTrees=10 | val AUC-PR=0.6728, AUC-ROC=0.8726, F0.5=0.6353\n[RF] depth=15, numTrees=15 | val AUC-PR=0.6757, AUC-ROC=0.8747, F0.5=0.6412\n[RF] depth=15, numTrees=20 | val AUC-PR=0.6796, AUC-ROC=0.8758, F0.5=0.6417\n\nBest RF config on val:\n{'maxDepth': 15, 'numTrees': 20, 'metrics': {'auc_pr': 0.6796402894156596, 'auc_roc': 0.8757719392859618, 'f0_5': 0.6417282423660131, 'precision': 0.6499919152552913, 'recall': 0.6106730714547808}}\n"
     ]
    }
   ],
   "source": [
    "numTrees_grid = [10,15,20]\n",
    "maxDepth_grid = [5, 8, 10,15]   \n",
    "\n",
    "best_rf = None\n",
    "best_cfg = None\n",
    "best_score = float(\"-inf\")\n",
    "\n",
    "for maxDepth in maxDepth_grid:\n",
    "    no_improve_rounds = 0\n",
    "    last_best_for_this_depth = float(\"-inf\")\n",
    "\n",
    "    for numTrees in numTrees_grid:\n",
    "        model, metrics = train_rf_and_eval(\n",
    "            df_train_undersampled,\n",
    "            df_val_2018,\n",
    "            assembler,\n",
    "            label_col,\n",
    "            num_trees=numTrees,\n",
    "            max_depth=maxDepth\n",
    "        )\n",
    "\n",
    "        auc_pr = metrics[\"auc_pr\"]\n",
    "\n",
    "        print(\n",
    "            f\"[RF] depth={maxDepth}, numTrees={numTrees} | \"\n",
    "            f\"val AUC-PR={auc_pr:.4f}, AUC-ROC={metrics['auc_roc']:.4f}, \"\n",
    "            f\"F0.5={metrics['f0_5']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if auc_pr > best_score:\n",
    "            best_score = auc_pr\n",
    "            best_rf = model\n",
    "            best_cfg = {\n",
    "                \"maxDepth\": maxDepth,\n",
    "                \"numTrees\": numTrees,\n",
    "                \"metrics\": metrics\n",
    "            }\n",
    "\n",
    "        if auc_pr > last_best_for_this_depth + 0.001:\n",
    "            last_best_for_this_depth = auc_pr\n",
    "            no_improve_rounds = 0\n",
    "        else:\n",
    "            no_improve_rounds += 1\n",
    "\n",
    "        if no_improve_rounds >= 1:\n",
    "            print(f\"  -> early stop on numTrees for depth={maxDepth}\")\n",
    "            break\n",
    "\n",
    "print(\"\\nBest RF config on val:\")\n",
    "print(best_cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fb9e00b-8a49-41d1-9027-04fcaca61f2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "[RF] depth=5, numTrees=20 | val AUC-PR=0.5694, AUC-ROC=0.8377, F0.5=0.5662\n",
    "[RF] depth=5, numTrees=30 | val AUC-PR=0.5678, AUC-ROC=0.8310, F0.5=0.5734\n",
    "  -> early stop on numTrees for depth=5\n",
    "[RF] depth=8, numTrees=20 | val AUC-PR=0.6142, AUC-ROC=0.8525, F0.5=0.6121\n",
    "[RF] depth=8, numTrees=30 | val AUC-PR=0.6130, AUC-ROC=0.8507, F0.5=0.6085\n",
    "  -> early stop on numTrees for depth=8\n",
    "[RF] depth=10, numTrees=20 | val AUC-PR=0.6364, AUC-ROC=0.8599, F0.5=0.6249\n",
    "[RF] depth=10, numTrees=30 | val AUC-PR=0.6357, AUC-ROC=0.8584, F0.5=0.6224\n",
    "  -> early stop on numTrees for depth=10\n",
    "\n",
    "Best RF config on val:\n",
    "{'maxDepth': 10, 'numTrees': 20, 'metrics': {'auc_pr': 0.636412025003994, 'auc_roc': 0.8599396284860885, 'f0_5': 0.6249493724262329, 'precision': 0.643160930363743, 'recall': 0.5613673173509668}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b261002d-4a58-4e73-af0c-ea735bd19953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train/Test Final RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db5811d7-4af3-4edb-b484-4e54ee710945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using best RF config from validation:\n  maxDepth  = 15\n  numTrees  = 20\n===== Final Random Forest performance on TEST 2019 =====\nAUC-PR   = 0.6639\nAUC-ROC  = 0.8711\nF0.5     = 0.6376\nPrecision= 0.6474\nRecall   = 0.6013\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. Extract the best hyperparameters from validation results\n",
    "# ============================================================\n",
    "best_depth = best_cfg[\"maxDepth\"]\n",
    "best_trees = best_cfg[\"numTrees\"]\n",
    "\n",
    "print(\"Using best RF config from validation:\")\n",
    "print(f\"  maxDepth  = {best_depth}\")\n",
    "print(f\"  numTrees  = {best_trees}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Define the final RF model using the selected hyperparameters\n",
    "#    Note: This model will be re-trained on the full training set\n",
    "#    (2015–2017 undersampled data) before being evaluated on test.\n",
    "# ============================================================\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "rf_final = RandomForestClassifier(\n",
    "    labelCol=label_col,\n",
    "    featuresCol=\"features\",\n",
    "    numTrees=best_trees,      # best number of trees found on validation set\n",
    "    maxDepth=best_depth,      # best max depth from validation\n",
    "    maxBins=64,               # consistent with earlier settings\n",
    "    seed=42,\n",
    "    featureSubsetStrategy=\"sqrt\"  # common choice; ensures reproducibility\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3. Create a pipeline with the same VectorAssembler\n",
    "#    This ensures consistent feature preprocessing.\n",
    "# ============================================================\n",
    "rf_final_pipeline = Pipeline(stages=[assembler, rf_final])\n",
    "\n",
    "# ============================================================\n",
    "# 4. Fit the final model on the entire training dataset\n",
    "#    (Only training data should be used for learning parameters)\n",
    "# ============================================================\n",
    "rf_final_model = rf_final_pipeline.fit(df_train_undersampled)\n",
    "\n",
    "# ============================================================\n",
    "# 5. Generate predictions on the test set (2019 data)\n",
    "# ============================================================\n",
    "rf_test_pred = rf_final_model.transform(df_test_2019)\n",
    "\n",
    "# ============================================================\n",
    "# 6. Evaluate the final model using PR-AUC, ROC-AUC, and F0.5\n",
    "#    These metrics quantify performance on the unseen test set.\n",
    "# ============================================================\n",
    "rf_test_auc_pr  = evaluator_pr.evaluate(rf_test_pred)\n",
    "rf_test_auc_roc = evaluator_roc.evaluate(rf_test_pred)\n",
    "rf_test_f05, rf_test_prec, rf_test_rec = compute_fbeta(\n",
    "    rf_test_pred,\n",
    "    label_col,\n",
    "    prediction_col=\"prediction\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 7. Print the final test performance\n",
    "# ============================================================\n",
    "print(\"===== Final Random Forest performance on TEST 2019 =====\")\n",
    "print(f\"AUC-PR   = {rf_test_auc_pr:.4f}\")\n",
    "print(f\"AUC-ROC  = {rf_test_auc_roc:.4f}\")\n",
    "print(f\"F0.5     = {rf_test_f05:.4f}\")\n",
    "print(f\"Precision= {rf_test_prec:.4f}\")\n",
    "print(f\"Recall   = {rf_test_rec:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Phase_3_Nicole",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}