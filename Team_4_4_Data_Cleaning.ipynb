{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cf8d28c-7dad-4b94-a474-f7bc9d9a6e4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Cleaning Notebook:\n",
    "\n",
    "Arun Agarwal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f3f9bc7-7c3a-4d61-8fd4-eb92d7ead48b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, count, mean, lit, first, desc, isnan, sum, avg, countDistinct, lit, unix_timestamp, to_timestamp, datediff\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b411d2eb-a100-4a05-a2e2-54b6e36f43f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Data Description:\n",
    "4 sources of data:\n",
    "1. Airlines Data: This is the raw data of flights information. You have 3 months, 6 months, 1 year, and full data from 2015 to 2019. Remember the maxima: \"Test, Test, Test\", so a lot of testing in smaller samples before scaling up! Location of the data? dbfs:/mnt/mids-w261/datasets_final_project_2022/parquet_airlines_data/, dbfs:/mnt/mids-w261/datasets_final_project_2022/parquet_airlines_data_1y/, etc. (Below the dbutils to get the folders)\n",
    "2. Weather Data: Raw data for weather information. Same as before, we are sharing 3 months, 6 months, 1 year\n",
    "3. Stations data: Extra information of the location of the different weather stations. Location dbfs:/mnt/mids-w261/datasets_final_project_2022/datasets_final_project_2022/stations_data/stations_with_neighbors.parquet/\n",
    "4. OTPW Data: This is our joined data (We joined Airlines and Weather). This is the main dataset for your project, the previous 3 are given for reference. You can attempt your own join for Extra Credit. Location dbfs:/mnt/mids-w261/OTPW_60M/OTPW_60M/ and more, several samples are given!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4394f8d3-8f8a-49ae-9200-8bde63604e9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0685bea-5a45-4ffa-aacc-b7bbf8ff8f6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/mids-w261/HW5/</td><td>HW5/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/OTPW_12M/</td><td>OTPW_12M/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/OTPW_1D_CSV/</td><td>OTPW_1D_CSV/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/OTPW_36M/</td><td>OTPW_36M/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/OTPW_3M/</td><td>OTPW_3M/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/OTPW_3M_2015.csv</td><td>OTPW_3M_2015.csv</td><td>1500620247</td><td>1741625185000</td></tr><tr><td>dbfs:/mnt/mids-w261/OTPW_3M_2015_delta/</td><td>OTPW_3M_2015_delta/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/OTPW_60M/</td><td>OTPW_60M/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/OTPW_60M_Backup/</td><td>OTPW_60M_Backup/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/airport-codes_csv.csv</td><td>airport-codes_csv.csv</td><td>6232459</td><td>1740508595000</td></tr><tr><td>dbfs:/mnt/mids-w261/checkpoint/</td><td>checkpoint/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/daniel_costa@berkeley.edu/</td><td>daniel_costa@berkeley.edu/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/datasets_final_project/</td><td>datasets_final_project/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/datasets_final_project_2022/</td><td>datasets_final_project_2022/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/final_project_winter_2025/</td><td>final_project_winter_2025/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/flight_airport_dictionary.parquet/</td><td>flight_airport_dictionary.parquet/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/student-groups/</td><td>student-groups/</td><td>0</td><td>1763996765061</td></tr><tr><td>dbfs:/mnt/mids-w261/students-groups/</td><td>students-groups/</td><td>0</td><td>1763996765061</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/mids-w261/HW5/",
         "HW5/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/OTPW_12M/",
         "OTPW_12M/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/OTPW_1D_CSV/",
         "OTPW_1D_CSV/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/OTPW_36M/",
         "OTPW_36M/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/OTPW_3M/",
         "OTPW_3M/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/OTPW_3M_2015.csv",
         "OTPW_3M_2015.csv",
         1500620247,
         1741625185000
        ],
        [
         "dbfs:/mnt/mids-w261/OTPW_3M_2015_delta/",
         "OTPW_3M_2015_delta/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/OTPW_60M/",
         "OTPW_60M/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/OTPW_60M_Backup/",
         "OTPW_60M_Backup/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/airport-codes_csv.csv",
         "airport-codes_csv.csv",
         6232459,
         1740508595000
        ],
        [
         "dbfs:/mnt/mids-w261/checkpoint/",
         "checkpoint/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/daniel_costa@berkeley.edu/",
         "daniel_costa@berkeley.edu/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/datasets_final_project/",
         "datasets_final_project/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/datasets_final_project_2022/",
         "datasets_final_project_2022/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/final_project_winter_2025/",
         "final_project_winter_2025/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/flight_airport_dictionary.parquet/",
         "flight_airport_dictionary.parquet/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/student-groups/",
         "student-groups/",
         0,
         1763996765061
        ],
        [
         "dbfs:/mnt/mids-w261/students-groups/",
         "students-groups/",
         0,
         1763996765061
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_BASE_DIR = \"dbfs:/mnt/mids-w261/\"\n",
    "display(dbutils.fs.ls(f\"{data_BASE_DIR}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01f9b436-da2a-4e21-9b47-1eac19a4f125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Airline Data    \n",
    "df_flights = spark.read.parquet(f\"dbfs:/mnt/mids-w261/datasets_final_project_2022/parquet_airlines_data_3m/\")\n",
    "display(df_flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebe332bf-8d01-41ec-9461-5e134b251a16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Weather data\n",
    "df_weather = spark.read.parquet(f\"dbfs:/mnt/mids-w261/datasets_final_project_2022/parquet_weather_data_3m/\")\n",
    "display(df_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87ab20af-b5e0-44ab-8562-7938f99074f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Stations data      \n",
    "df_stations = spark.read.parquet(f\"dbfs:/mnt/mids-w261/datasets_final_project_2022/stations_data/stations_with_neighbors.parquet/\")\n",
    "display(df_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c2bfb8f-c1db-4b4f-a575-a6aa173bf2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# OTPW\n",
    "df_otpw = spark.read.format(\"csv\").option(\"header\",\"true\").load(f\"dbfs:/mnt/mids-w261/OTPW_3M_2015.csv\")\n",
    "display(df_otpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "735d7cc1-6bf9-4807-bada-f2f6022b03cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Group Checkpoint Folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edf43ae8-b2bf-4a04-b102-6e1a3f019d74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists: dbfs:/student-groups/Group_04_04\n"
     ]
    }
   ],
   "source": [
    "# Create folder (RUN THIS ONCE)\n",
    "section = \"04\"\n",
    "number = \"04\"\n",
    "folder_path = f\"dbfs:/student-groups/Group_{section}_{number}\"\n",
    "\n",
    "# Check if folder exists\n",
    "try:\n",
    "    dbutils.fs.ls(folder_path)\n",
    "    print(f\"Folder already exists: {folder_path}\")\n",
    "except Exception as e:\n",
    "    # If folder doesn't exist, create it\n",
    "    dbutils.fs.mkdirs(folder_path)\n",
    "    print(f\"Created folder: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f28bd42-4088-4cf2-a470-fbdb49ba45dc",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"path\":329},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762025716148}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/student-groups/Group_04_04/appendix_b_column_classification.csv</td><td>appendix_b_column_classification.csv</td><td>8138</td><td>1762036459000</td></tr><tr><td>dbfs:/student-groups/Group_04_04/checkpoints/</td><td>checkpoints/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_custom_3M_initial_features.parquet/</td><td>df_custom_3M_initial_features.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_custom_3M_test_data.parquet/</td><td>df_custom_3M_test_data.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_custom_3M_train_data.parquet/</td><td>df_custom_3M_train_data.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_otpw.parquet/</td><td>df_otpw.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_otpw_3M_baseline_features.parquet/</td><td>df_otpw_3M_baseline_features.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_otpw_3M_clean.parquet/</td><td>df_otpw_3M_clean.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_otpw_3M_features.parquet/</td><td>df_otpw_3M_features.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_otpw_3M_initial_features.parquet/</td><td>df_otpw_3M_initial_features.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_otpw_3M_test_data.parquet/</td><td>df_otpw_3M_test_data.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_otpw_3M_train_data.parquet/</td><td>df_otpw_3M_train_data.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_otpw_3M_validation_data.parquet/</td><td>df_otpw_3M_validation_data.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_otpw_3m.parquet/</td><td>df_otpw_3m.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_weather.parquet/</td><td>df_weather.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/df_weather_3m.parquet/</td><td>df_weather_3m.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/otpw_3m.parquet/</td><td>otpw_3m.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/otpw_3m_clean.parquet/</td><td>otpw_3m_clean.parquet/</td><td>0</td><td>1763996805686</td></tr><tr><td>dbfs:/student-groups/Group_04_04/otpw_3m_imputed.parquet/</td><td>otpw_3m_imputed.parquet/</td><td>0</td><td>1763996805686</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/student-groups/Group_04_04/appendix_b_column_classification.csv",
         "appendix_b_column_classification.csv",
         8138,
         1762036459000
        ],
        [
         "dbfs:/student-groups/Group_04_04/checkpoints/",
         "checkpoints/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_custom_3M_initial_features.parquet/",
         "df_custom_3M_initial_features.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_custom_3M_test_data.parquet/",
         "df_custom_3M_test_data.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_custom_3M_train_data.parquet/",
         "df_custom_3M_train_data.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_otpw.parquet/",
         "df_otpw.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_otpw_3M_baseline_features.parquet/",
         "df_otpw_3M_baseline_features.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_otpw_3M_clean.parquet/",
         "df_otpw_3M_clean.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_otpw_3M_features.parquet/",
         "df_otpw_3M_features.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_otpw_3M_initial_features.parquet/",
         "df_otpw_3M_initial_features.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_otpw_3M_test_data.parquet/",
         "df_otpw_3M_test_data.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_otpw_3M_train_data.parquet/",
         "df_otpw_3M_train_data.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_otpw_3M_validation_data.parquet/",
         "df_otpw_3M_validation_data.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_otpw_3m.parquet/",
         "df_otpw_3m.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_weather.parquet/",
         "df_weather.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/df_weather_3m.parquet/",
         "df_weather_3m.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/otpw_3m.parquet/",
         "otpw_3m.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/otpw_3m_clean.parquet/",
         "otpw_3m_clean.parquet/",
         0,
         1763996805686
        ],
        [
         "dbfs:/student-groups/Group_04_04/otpw_3m_imputed.parquet/",
         "otpw_3m_imputed.parquet/",
         0,
         1763996805686
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(f\"{folder_path}\"))\n",
    "#display(dbutils.fs.ls(f\"{folder_path}/checkpoints/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dee64448-45e8-454e-8554-a81938c0b97c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-joined dataset\nNum rows: 5,704,114\nNum cols: 105\nroot\n |-- FL_DATE: date (nullable = true)\n |-- OP_UNIQUE_CARRIER: string (nullable = true)\n |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n |-- ORIGIN: string (nullable = true)\n |-- DEST: string (nullable = true)\n |-- CRS_DEP_TIME: integer (nullable = true)\n |-- ORIGIN_AIRPORT_ID: integer (nullable = true)\n |-- departure_hour: integer (nullable = true)\n |-- prediction_utc: timestamp (nullable = true)\n |-- origin_obs_utc: timestamp (nullable = true)\n |-- asof_minutes: long (nullable = true)\n |-- YEAR: integer (nullable = true)\n |-- QUARTER: integer (nullable = true)\n |-- DAY_OF_MONTH: integer (nullable = true)\n |-- DAY_OF_WEEK: integer (nullable = true)\n |-- CRS_ARR_TIME: integer (nullable = true)\n |-- ORIGIN_STATE_ABR: string (nullable = true)\n |-- DEST_AIRPORT_ID: integer (nullable = true)\n |-- DEST_STATE_ABR: string (nullable = true)\n |-- HourlyDewPointTemperature: double (nullable = true)\n |-- HourlyPrecipitation: double (nullable = true)\n |-- HourlyWindSpeed: double (nullable = true)\n |-- HourlyWindDirection: double (nullable = true)\n |-- HourlyWindGustSpeed: double (nullable = true)\n |-- HourlyVisibility: double (nullable = true)\n |-- HourlyRelativeHumidity: double (nullable = true)\n |-- HourlyAltimeterSetting: double (nullable = true)\n |-- origin_airport_lat: double (nullable = true)\n |-- origin_airport_lon: double (nullable = true)\n |-- dest_airport_lat: double (nullable = true)\n |-- dest_airport_lon: double (nullable = true)\n |-- origin_station_dis: double (nullable = true)\n |-- dest_station_dis: double (nullable = true)\n |-- origin_type: string (nullable = true)\n |-- dest_type: string (nullable = true)\n |-- DEP_DEL15: integer (nullable = true)\n |-- CANCELLED: integer (nullable = true)\n |-- CANCELLATION_CODE: string (nullable = true)\n |-- DIVERTED: integer (nullable = true)\n |-- departure_month: integer (nullable = true)\n |-- departure_dayofweek: integer (nullable = true)\n |-- is_weekend: integer (nullable = true)\n |-- season: string (nullable = true)\n |-- is_peak_hour: integer (nullable = true)\n |-- is_peak_month: integer (nullable = true)\n |-- time_of_day_early_morning: integer (nullable = true)\n |-- time_of_day_morning: integer (nullable = true)\n |-- time_of_day_afternoon: integer (nullable = true)\n |-- time_of_day_evening: integer (nullable = true)\n |-- time_of_day_night: integer (nullable = true)\n |-- rolling_origin_num_delays_24h: long (nullable = true)\n |-- dep_delay15_24h_rolling_avg_by_origin: double (nullable = true)\n |-- dep_delay15_24h_rolling_avg_by_origin_carrier: double (nullable = true)\n |-- dep_delay15_24h_rolling_avg_by_origin_dayofweek: double (nullable = true)\n |-- is_holiday_window: integer (nullable = true)\n |-- weather_severity_index: double (nullable = true)\n |-- distance_medium: integer (nullable = true)\n |-- distance_long: integer (nullable = true)\n |-- distance_very_long: integer (nullable = true)\n |-- weather_condition_category: string (nullable = true)\n |-- airport_traffic_density: double (nullable = true)\n |-- carrier_flight_count: long (nullable = true)\n |-- weather_obs_lag_hours: double (nullable = true)\n |-- log_distance: double (nullable = true)\n |-- is_rainy: integer (nullable = true)\n |-- prev_flight_dep_del15: double (nullable = true)\n |-- prev_flight_crs_elapsed_time: double (nullable = true)\n |-- hours_since_prev_flight: double (nullable = true)\n |-- is_first_flight_of_aircraft: integer (nullable = true)\n |-- turnaround_category: string (nullable = true)\n |-- is_business_hours: integer (nullable = true)\n |-- is_holiday_month: integer (nullable = true)\n |-- num_airport_wide_delays: long (nullable = true)\n |-- temp_dest_count: long (nullable = true)\n |-- oncoming_flights: long (nullable = true)\n |-- prior_day_delay_rate: double (nullable = true)\n |-- time_based_congestion_ratio: double (nullable = true)\n |-- sky_condition_parsed: string (nullable = true)\n |-- rapid_weather_change: integer (nullable = true)\n |-- temp_anomaly: double (nullable = true)\n |-- dep_time_sin: double (nullable = true)\n |-- dep_time_cos: double (nullable = true)\n |-- arr_time_sin: double (nullable = true)\n |-- arr_time_cos: double (nullable = true)\n |-- day_of_week_sin: double (nullable = true)\n |-- day_of_week_cos: double (nullable = true)\n |-- month_sin: double (nullable = true)\n |-- month_cos: double (nullable = true)\n |-- wind_direction_sin: double (nullable = true)\n |-- wind_direction_cos: double (nullable = true)\n |-- extreme_precipitation: integer (nullable = true)\n |-- extreme_wind: integer (nullable = true)\n |-- extreme_temperature: integer (nullable = true)\n |-- low_visibility: integer (nullable = true)\n |-- extreme_weather_score: double (nullable = true)\n |-- origin_degree_centrality: double (nullable = true)\n |-- dest_degree_centrality: double (nullable = true)\n |-- carrier_delay_stddev: double (nullable = true)\n |-- pagerank: double (nullable = true)\n |-- days_since_epoch: integer (nullable = true)\n |-- origin_1yr_delay_rate: double (nullable = true)\n |-- dest_1yr_delay_rate: double (nullable = true)\n |-- rolling_30day_volume: long (nullable = true)\n |-- route_1yr_volume: long (nullable = true)\n |-- DEP_DELAY: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# df_otpw_3m = spark.read.parquet(\"dbfs:/student-groups/Group_4_4/2015_final_feature_engineered_data_with_dep_delay\")\n",
    "\n",
    "# print(\"Loaded pre-joined dataset\")\n",
    "# print(f\"Num rows: {df_otpw_3m.count():,}\")\n",
    "# print(f\"Num cols: {len(df_otpw_3m.columns)}\")\n",
    "# df_otpw_3m.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c5ccbd3-9e1a-4610-8512-dcaf51000320",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n1. DATASET OVERVIEW\n--------------------------------------------------------------------------------\nTotal rows: 5,704,114\n\nDEP_DELAY:\n  - Null values: 0 (0.00%)\n  - Non-null values: 5,704,114 (100.00%)\n\nDEP_DEL15:\n  - Null values: 0 (0.00%)\n  - Non-null values: 5,704,114 (100.00%)\n\n\n2. DEP_DELAY DESCRIPTIVE STATISTICS\n--------------------------------------------------------------------------------\n\nBasic Statistics:\n       count: 5704114\n        mean: 0.18390077757912973\n      stddev: 0.3874032884423996\n         min: 0.0\n         max: 1.0\n         25%: 0.0\n         50%: 0.0\n         75%: 0.0\n\nAdditional Percentiles:\n  1st percentile:  0.00\n  5th percentile:  0.00\n  10th percentile: 0.00\n  90th percentile: 1.00\n  95th percentile: 1.00\n  99th percentile: 1.00\n\nDistribution of DEP_DELAY (minutes):\n  0 to 15 (On-time)   :  5,704,114 (100.00%)\n\n\n3. DEP_DEL15 ANALYSIS (Classification Target)\n--------------------------------------------------------------------------------\n\nClass Distribution:\n  DEP_DEL15 = 0:  4,655,123 (81.61%) - On-time (< 15 min)\n  DEP_DEL15 = 1:  1,048,991 (18.39%) - Delayed (>= 15 min)\n\nClass Imbalance Ratio (0:1): 4.44:1\n\n\n4. RELATIONSHIP BETWEEN DEP_DELAY AND DEP_DEL15\n--------------------------------------------------------------------------------\n\nDEP_DELAY statistics by DEP_DEL15 class:\n\n  DEP_DEL15 = 0 (On-time):\n    Count:    4,655,123\n    Mean:          0.00 minutes\n    Std Dev:       0.00 minutes\n    Median:        0.00 minutes\n    Min:           0.00 minutes\n    Max:           0.00 minutes\n\n  DEP_DEL15 = 1 (Delayed):\n    Count:    1,048,991\n    Mean:          1.00 minutes\n    Std Dev:       0.00 minutes\n    Median:        1.00 minutes\n    Min:           1.00 minutes\n    Max:           1.00 minutes\n\n\n5. DATA QUALITY CHECKS\n--------------------------------------------------------------------------------\n\nInconsistencies (DEP_DEL15=1 but DEP_DELAY < 15): 1,048,991\nInconsistencies (DEP_DEL15=0 but DEP_DELAY >= 15): 0\nRows where both DEP_DEL15 and DEP_DELAY are NULL: 0\nRows where DEP_DEL15 is NULL but DEP_DELAY is not: 0\n\nExtreme values:\n  DEP_DELAY < -100 minutes: 0\n  DEP_DELAY > 500 minutes:  0\n\n\n6. CORRELATION ANALYSIS\n--------------------------------------------------------------------------------\n\nPearson Correlation (DEP_DELAY vs DEP_DEL15): 1.0000\n\n================================================================================\nANALYSIS COMPLETE\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import col, when, count, mean, lit, first, desc, isnan, sum as spark_sum, avg, countDistinct, lit, unix_timestamp, to_timestamp, datediff\n",
    "# import pyspark.sql.functions as F\n",
    "\n",
    "# # ============================================================================\n",
    "# # 1. BASIC COUNTS AND NULL CHECKS\n",
    "# # ============================================================================\n",
    "# print(\"\\n1. DATASET OVERVIEW\")\n",
    "# print(\"-\" * 80)\n",
    "\n",
    "# total_rows = df_otpw_3m.count()\n",
    "# print(f\"Total rows: {total_rows:,}\")\n",
    "\n",
    "# null_checks = df_otpw_3m.select(\n",
    "#     F.count(F.when(F.col(\"DEP_DELAY\").isNull(), 1)).alias(\"DEP_DELAY_nulls\"),\n",
    "#     F.count(F.when(F.col(\"DEP_DEL15\").isNull(), 1)).alias(\"DEP_DEL15_nulls\"),\n",
    "#     F.count(F.when(F.col(\"DEP_DELAY\").isNotNull(), 1)).alias(\"DEP_DELAY_non_null\"),\n",
    "#     F.count(F.when(F.col(\"DEP_DEL15\").isNotNull(), 1)).alias(\"DEP_DEL15_non_null\")\n",
    "# ).collect()[0]\n",
    "\n",
    "# print(f\"\\nDEP_DELAY:\")\n",
    "# print(f\"  - Null values: {null_checks['DEP_DELAY_nulls']:,} ({null_checks['DEP_DELAY_nulls']/total_rows*100:.2f}%)\")\n",
    "# print(f\"  - Non-null values: {null_checks['DEP_DELAY_non_null']:,} ({null_checks['DEP_DELAY_non_null']/total_rows*100:.2f}%)\")\n",
    "\n",
    "# print(f\"\\nDEP_DEL15:\")\n",
    "# print(f\"  - Null values: {null_checks['DEP_DEL15_nulls']:,} ({null_checks['DEP_DEL15_nulls']/total_rows*100:.2f}%)\")\n",
    "# print(f\"  - Non-null values: {null_checks['DEP_DEL15_non_null']:,} ({null_checks['DEP_DEL15_non_null']/total_rows*100:.2f}%)\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # 2. DEP_DELAY DESCRIPTIVE STATISTICS\n",
    "# # ============================================================================\n",
    "# print(\"\\n\\n2. DEP_DELAY DESCRIPTIVE STATISTICS\")\n",
    "# print(\"-\" * 80)\n",
    "\n",
    "# delay_stats = df_otpw_3m.select(\"DEP_DELAY\").summary(\"count\", \"mean\", \"stddev\", \"min\", \"max\", \"25%\", \"50%\", \"75%\")\n",
    "# print(\"\\nBasic Statistics:\")\n",
    "# for row in delay_stats.collect():\n",
    "#     print(f\"  {row[0]:>10s}: {row[1]}\")\n",
    "\n",
    "# # Additional percentiles\n",
    "# percentiles = df_otpw_3m.select(\n",
    "#     F.percentile_approx(\"DEP_DELAY\", [0.01, 0.05, 0.10, 0.90, 0.95, 0.99]).alias(\"percentiles\")\n",
    "# ).collect()[0]['percentiles']\n",
    "\n",
    "# print(f\"\\nAdditional Percentiles:\")\n",
    "# print(f\"  1st percentile:  {percentiles[0]:.2f}\")\n",
    "# print(f\"  5th percentile:  {percentiles[1]:.2f}\")\n",
    "# print(f\"  10th percentile: {percentiles[2]:.2f}\")\n",
    "# print(f\"  90th percentile: {percentiles[3]:.2f}\")\n",
    "# print(f\"  95th percentile: {percentiles[4]:.2f}\")\n",
    "# print(f\"  99th percentile: {percentiles[5]:.2f}\")\n",
    "\n",
    "# # Distribution bins\n",
    "# print(\"\\nDistribution of DEP_DELAY (minutes):\")\n",
    "# delay_distribution = df_otpw_3m.groupBy(\n",
    "#     F.when(F.col(\"DEP_DELAY\") < -30, \"< -30 (Very early)\")\n",
    "#     .when((F.col(\"DEP_DELAY\") >= -30) & (F.col(\"DEP_DELAY\") < -15), \"-30 to -15\")\n",
    "#     .when((F.col(\"DEP_DELAY\") >= -15) & (F.col(\"DEP_DELAY\") < 0), \"-15 to 0\")\n",
    "#     .when((F.col(\"DEP_DELAY\") >= 0) & (F.col(\"DEP_DELAY\") < 15), \"0 to 15 (On-time)\")\n",
    "#     .when((F.col(\"DEP_DELAY\") >= 15) & (F.col(\"DEP_DELAY\") < 30), \"15 to 30\")\n",
    "#     .when((F.col(\"DEP_DELAY\") >= 30) & (F.col(\"DEP_DELAY\") < 60), \"30 to 60\")\n",
    "#     .when((F.col(\"DEP_DELAY\") >= 60) & (F.col(\"DEP_DELAY\") < 120), \"60 to 120\")\n",
    "#     .when(F.col(\"DEP_DELAY\") >= 120, \">= 120 (Severe)\")\n",
    "#     .otherwise(\"NULL\").alias(\"delay_range\")\n",
    "# ).agg(\n",
    "#     F.count(\"*\").alias(\"count\")\n",
    "# ).orderBy(\"delay_range\")\n",
    "\n",
    "# for row in delay_distribution.collect():\n",
    "#     pct = (row['count'] / total_rows) * 100\n",
    "#     print(f\"  {row['delay_range']:20s}: {row['count']:>10,} ({pct:>5.2f}%)\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # 3. DEP_DEL15 ANALYSIS (Binary Classification Target)\n",
    "# # ============================================================================\n",
    "# print(\"\\n\\n3. DEP_DEL15 ANALYSIS (Classification Target)\")\n",
    "# print(\"-\" * 80)\n",
    "\n",
    "# del15_distribution = df_otpw_3m.groupBy(\"DEP_DEL15\").agg(\n",
    "#     F.count(\"*\").alias(\"count\")\n",
    "# ).orderBy(\"DEP_DEL15\")\n",
    "\n",
    "# print(\"\\nClass Distribution:\")\n",
    "# for row in del15_distribution.collect():\n",
    "#     if row['DEP_DEL15'] is not None:\n",
    "#         pct = (row['count'] / total_rows) * 100\n",
    "#         label = \"On-time (< 15 min)\" if row['DEP_DEL15'] == 0 else \"Delayed (>= 15 min)\"\n",
    "#         print(f\"  DEP_DEL15 = {row['DEP_DEL15']}: {row['count']:>10,} ({pct:>5.2f}%) - {label}\")\n",
    "#     else:\n",
    "#         pct = (row['count'] / total_rows) * 100\n",
    "#         print(f\"  DEP_DEL15 = NULL: {row['count']:>10,} ({pct:>5.2f}%)\")\n",
    "\n",
    "# # Calculate class imbalance ratio\n",
    "# non_null_del15 = df_otpw_3m.filter(F.col(\"DEP_DEL15\").isNotNull())\n",
    "# class_counts = non_null_del15.groupBy(\"DEP_DEL15\").count().collect()\n",
    "# if len(class_counts) == 2:\n",
    "#     count_0 = next((r['count'] for r in class_counts if r['DEP_DEL15'] == 0), 0)\n",
    "#     count_1 = next((r['count'] for r in class_counts if r['DEP_DEL15'] == 1), 0)\n",
    "#     if count_1 > 0:\n",
    "#         imbalance_ratio = count_0 / count_1\n",
    "#         print(f\"\\nClass Imbalance Ratio (0:1): {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # 4. RELATIONSHIP BETWEEN DEP_DELAY AND DEP_DEL15\n",
    "# # ============================================================================\n",
    "# print(\"\\n\\n4. RELATIONSHIP BETWEEN DEP_DELAY AND DEP_DEL15\")\n",
    "# print(\"-\" * 80)\n",
    "\n",
    "# # Statistics grouped by DEP_DEL15\n",
    "# delay_by_del15 = df_otpw_3m.filter(F.col(\"DEP_DEL15\").isNotNull()).groupBy(\"DEP_DEL15\").agg(\n",
    "#     F.count(\"DEP_DELAY\").alias(\"count\"),\n",
    "#     F.mean(\"DEP_DELAY\").alias(\"mean_delay\"),\n",
    "#     F.stddev(\"DEP_DELAY\").alias(\"stddev_delay\"),\n",
    "#     F.min(\"DEP_DELAY\").alias(\"min_delay\"),\n",
    "#     F.max(\"DEP_DELAY\").alias(\"max_delay\"),\n",
    "#     F.expr(\"percentile_approx(DEP_DELAY, 0.5)\").alias(\"median_delay\")\n",
    "# ).orderBy(\"DEP_DEL15\")\n",
    "\n",
    "# print(\"\\nDEP_DELAY statistics by DEP_DEL15 class:\")\n",
    "# for row in delay_by_del15.collect():\n",
    "#     label = \"On-time\" if row['DEP_DEL15'] == 0 else \"Delayed\"\n",
    "#     print(f\"\\n  DEP_DEL15 = {row['DEP_DEL15']} ({label}):\")\n",
    "#     print(f\"    Count:   {row['count']:>10,}\")\n",
    "#     print(f\"    Mean:    {row['mean_delay']:>10.2f} minutes\")\n",
    "#     print(f\"    Std Dev: {row['stddev_delay']:>10.2f} minutes\")\n",
    "#     print(f\"    Median:  {row['median_delay']:>10.2f} minutes\")\n",
    "#     print(f\"    Min:     {row['min_delay']:>10.2f} minutes\")\n",
    "#     print(f\"    Max:     {row['max_delay']:>10.2f} minutes\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # 5. DATA QUALITY CHECKS\n",
    "# # ============================================================================\n",
    "# print(\"\\n\\n5. DATA QUALITY CHECKS\")\n",
    "# print(\"-\" * 80)\n",
    "\n",
    "# # Check for inconsistencies: DEP_DEL15=1 but DEP_DELAY < 15\n",
    "# inconsistent_delayed = df_otpw_3m.filter(\n",
    "#     (F.col(\"DEP_DEL15\") == 1) & (F.col(\"DEP_DELAY\") < 15)\n",
    "# ).count()\n",
    "# print(f\"\\nInconsistencies (DEP_DEL15=1 but DEP_DELAY < 15): {inconsistent_delayed:,}\")\n",
    "\n",
    "# # Check for inconsistencies: DEP_DEL15=0 but DEP_DELAY >= 15\n",
    "# inconsistent_ontime = df_otpw_3m.filter(\n",
    "#     (F.col(\"DEP_DEL15\") == 0) & (F.col(\"DEP_DELAY\") >= 15)\n",
    "# ).count()\n",
    "# print(f\"Inconsistencies (DEP_DEL15=0 but DEP_DELAY >= 15): {inconsistent_ontime:,}\")\n",
    "\n",
    "# # Rows where both are null\n",
    "# both_null = df_otpw_3m.filter(\n",
    "#     F.col(\"DEP_DEL15\").isNull() & F.col(\"DEP_DELAY\").isNull()\n",
    "# ).count()\n",
    "# print(f\"Rows where both DEP_DEL15 and DEP_DELAY are NULL: {both_null:,}\")\n",
    "\n",
    "# # Rows where DEP_DEL15 is null but DEP_DELAY is not\n",
    "# del15_null_delay_not = df_otpw_3m.filter(\n",
    "#     F.col(\"DEP_DEL15\").isNull() & F.col(\"DEP_DELAY\").isNotNull()\n",
    "# ).count()\n",
    "# print(f\"Rows where DEP_DEL15 is NULL but DEP_DELAY is not: {del15_null_delay_not:,}\")\n",
    "\n",
    "# # Check for extreme values\n",
    "# extreme_negative = df_otpw_3m.filter(F.col(\"DEP_DELAY\") < -100).count()\n",
    "# extreme_positive = df_otpw_3m.filter(F.col(\"DEP_DELAY\") > 500).count()\n",
    "# print(f\"\\nExtreme values:\")\n",
    "# print(f\"  DEP_DELAY < -100 minutes: {extreme_negative:,}\")\n",
    "# print(f\"  DEP_DELAY > 500 minutes:  {extreme_positive:,}\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # 6. CORRELATION ANALYSIS\n",
    "# # ============================================================================\n",
    "# print(\"\\n\\n6. CORRELATION ANALYSIS\")\n",
    "# print(\"-\" * 80)\n",
    "\n",
    "# # Calculate correlation between numeric representation\n",
    "# correlation = df_otpw_3m.stat.corr(\"DEP_DELAY\", \"DEP_DEL15\")\n",
    "# print(f\"\\nPearson Correlation (DEP_DELAY vs DEP_DEL15): {correlation:.4f}\")\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 80)\n",
    "# print(\"ANALYSIS COMPLETE\")\n",
    "# print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d972b16-ec0b-449d-8f3b-102918ac2be1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nDropping existing (incorrect) DEP_DELAY column from final dataset...\nColumns after drop: 104\nFinal dataset shape: 5704114 rows, 104 columns\nFinal dataset columns include DEP_DELAY: False\n\nDataset with dep_delay shape: 5819079 rows, 75 columns\nFound 'DEP_DELAY' column in source dataset\n\nSample of DEP_DELAY values to be joined:\n+-------+------------------+\n|summary|         DEP_DELAY|\n+-------+------------------+\n|  count|           5732926|\n|   mean| 9.370158275198389|\n| stddev|37.080942496787074|\n|    min|             -82.0|\n|    max|            1988.0|\n+-------+------------------+\n\n\nFirst 10 rows:\n+----------+-----------------+-----------------+------+----+------------+-----------------+---------+\n|   FL_DATE|OP_UNIQUE_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|ORIGIN_AIRPORT_ID|DEP_DELAY|\n+----------+-----------------+-----------------+------+----+------------+-----------------+---------+\n|2015-01-01|               DL|             1199|   STL| ATL|        1712|            15016|    -12.0|\n|2015-01-01|               DL|             1341|   GSP| ATL|        1510|            11996|     -3.0|\n|2015-01-01|               DL|             1427|   ATL| FLL|        1830|            10397|      2.0|\n|2015-01-01|               DL|              196|   MCI| ATL|         820|            13198|     -7.0|\n|2015-01-01|               DL|             2325|   LGA| FLL|         800|            12953|      0.0|\n|2015-01-01|               WN|             2499|   IND| FLL|        1125|            12339|     -3.0|\n|2015-01-01|               WN|              710|   LAS| FLL|        1520|            12889|     12.0|\n|2015-01-02|               AA|             1513|   DFW| ATL|         700|            11298|     -8.0|\n|2015-01-02|               DL|             1139|   DCA| ATL|         800|            11278|     -5.0|\n|2015-01-02|               DL|             1977|   ORD| ATL|        1800|            13930|     -6.0|\n+----------+-----------------+-----------------+------+----+------------+-----------------+---------+\nonly showing top 10 rows\n\nFinal dataset with DEP_DELAY: 5704114 rows, 105 columns\nIncludes DEP_DELAY: True\n\nNull values in DEP_DELAY after join: 0\n\nDEP_DELAY statistics (should show continuous values, not just 0/1):\n+-------+-----------------+\n|summary|        DEP_DELAY|\n+-------+-----------------+\n|  count|          5704114|\n|   mean|9.301552002642303|\n| stddev|36.88193435408238|\n|    min|            -82.0|\n|    max|           1988.0|\n+-------+-----------------+\n\nNumber of distinct DEP_DELAY values: 1211 (should be >> 2)\n\nSample of data with both DEP_DELAY (continuous) and DEP_DEL15 (binary):\n+----------+-----------------+------+----+---------+---------+\n|   FL_DATE|OP_UNIQUE_CARRIER|ORIGIN|DEST|DEP_DELAY|DEP_DEL15|\n+----------+-----------------+------+----+---------+---------+\n|2015-07-23|               DL|   BHM| ATL|     23.0|        1|\n|2015-07-13|               DL|   BHM| ATL|     -8.0|        0|\n|2015-02-14|               DL|   BHM| ATL|     -9.0|        0|\n|2015-10-20|               DL|   BHM| ATL|     -8.0|        0|\n|2015-02-28|               DL|   BHM| ATL|     -2.0|        0|\n|2015-04-19|               DL|   BHM| ATL|     25.0|        1|\n|2015-10-04|               DL|   BHM| ATL|     -2.0|        0|\n|2015-05-30|               DL|   BHM| ATL|     -1.0|        0|\n|2015-12-17|               DL|   BHM| ATL|     -1.0|        0|\n|2015-07-23|               DL|   BHM| ATL|     -5.0|        0|\n|2015-04-23|               DL|   BHM| ATL|     -3.0|        0|\n|2015-08-11|               DL|   BHM| ATL|     14.0|        0|\n|2015-02-25|               EV|   BHM| ATL|     -1.0|        0|\n|2015-07-10|               DL|   BHM| ATL|     67.0|        1|\n|2015-06-15|               DL|   BHM| ATL|      0.0|        0|\n|2015-03-30|               DL|   BHM| ATL|     -2.0|        0|\n|2015-10-22|               DL|   BHM| ATL|      6.0|        0|\n|2015-04-16|               DL|   BHM| ATL|      0.0|        0|\n|2015-06-20|               DL|   BHM| ATL|    134.0|        1|\n|2015-05-21|               WN|   BHM| BWI|      0.0|        0|\n+----------+-----------------+------+----+---------+---------+\nonly showing top 20 rows\n\nVerifying DEP_DELAY and DEP_DEL15 relationship:\n+---------+---------+---------+---------+------------------+-------+\n|DEP_DEL15|DEP_DEL15|min_delay|max_delay|         avg_delay|  count|\n+---------+---------+---------+---------+------------------+-------+\n|        0|        0|    -82.0|     14.0|-2.013870525010832|4655123|\n|        1|        1|     15.0|   1988.0|59.516171254090835|1048991|\n+---------+---------+---------+---------+------------------+-------+\n\n\n================================================================================\nSUCCESS: Dataset with DEP_DELAY saved to: dbfs:/student-groups/Group_4_4/2015_final_feature_engineered_data_with_dep_delay\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"\n",
    "# Corrected script to add DEP_DELAY (continuous delay in minutes) back to the final dataset\n",
    "# FIXED: Now selects actual DEP_DELAY instead of DEP_DEL15\n",
    "# \"\"\"\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col\n",
    "# from pyspark.sql import functions as F\n",
    "\n",
    "# # Initialize Spark session (if not already available)\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# # Define file paths - adjust these to match your actual file locations\n",
    "# BASE_PATH = \"dbfs:/student-groups/Group_4_4/\"\n",
    "\n",
    "# # Load the final feature engineered dataset (without DEP_DELAY)\n",
    "# df_final = df_otpw_3m\n",
    "# if 'DEP_DELAY' in df_final.columns:\n",
    "#     print(\"\\nDropping existing (incorrect) DEP_DELAY column from final dataset...\")\n",
    "#     df_final = df_final.drop('DEP_DELAY')\n",
    "#     print(f\"Columns after drop: {len(df_final.columns)}\")\n",
    "\n",
    "# print(f\"Final dataset shape: {df_final.count()} rows, {len(df_final.columns)} columns\")\n",
    "# print(f\"Final dataset columns include DEP_DELAY: {'DEP_DELAY' in df_final.columns}\")\n",
    "\n",
    "# # Load the dataset before DEP_DELAY was removed (with DEP_DELAY)\n",
    "# # This could be your merged dataset or an earlier feature engineered version\n",
    "# dataset_with_dep_delay_path = f\"{BASE_PATH}JOINED_1Y_2015.parquet\"  # Adjust path as needed\n",
    "# df_with_dep_delay = spark.read.parquet(dataset_with_dep_delay_path)\n",
    "\n",
    "# print(f\"\\nDataset with dep_delay shape: {df_with_dep_delay.count()} rows, {len(df_with_dep_delay.columns)} columns\")\n",
    "\n",
    "# # Check which column name exists (DEP_DELAY vs dep_delay)\n",
    "# has_dep_delay = 'DEP_DELAY' in df_with_dep_delay.columns\n",
    "# has_dep_delay_lower = 'dep_delay' in df_with_dep_delay.columns\n",
    "\n",
    "# if has_dep_delay:\n",
    "#     print(f\"Found 'DEP_DELAY' column in source dataset\")\n",
    "#     delay_col_name = 'DEP_DELAY'\n",
    "# elif has_dep_delay_lower:\n",
    "#     print(f\"Found 'dep_delay' column in source dataset\")\n",
    "#     delay_col_name = 'dep_delay'\n",
    "# else:\n",
    "#     print(\"ERROR: Neither 'DEP_DELAY' nor 'dep_delay' found in source dataset!\")\n",
    "#     print(f\"Available columns: {df_with_dep_delay.columns}\")\n",
    "#     raise ValueError(\"DEP_DELAY column not found\")\n",
    "\n",
    "# # Select only DEP_DELAY and the key columns needed for joining\n",
    "# # Adjust join keys based on your data structure\n",
    "# join_keys = ['FL_DATE', 'OP_UNIQUE_CARRIER', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST', 'CRS_DEP_TIME', 'ORIGIN_AIRPORT_ID']\n",
    "\n",
    "# # CORRECTED: Select the actual DEP_DELAY (continuous minutes), not DEP_DEL15 (binary)\n",
    "# if delay_col_name == 'dep_delay':\n",
    "#     # If lowercase, alias it to uppercase for consistency\n",
    "#     df_dep_delay_only = df_with_dep_delay.select(*join_keys, col('dep_delay').alias('DEP_DELAY'))\n",
    "# else:\n",
    "#     # If already uppercase, use as-is\n",
    "#     df_dep_delay_only = df_with_dep_delay.select(*join_keys, 'DEP_DELAY')\n",
    "\n",
    "# # Show sample of what we're about to join\n",
    "# print(\"\\nSample of DEP_DELAY values to be joined:\")\n",
    "# df_dep_delay_only.select('DEP_DELAY').describe().show()\n",
    "# print(\"\\nFirst 10 rows:\")\n",
    "# df_dep_delay_only.show(10)\n",
    "\n",
    "# # Join DEP_DELAY back to the final dataset\n",
    "# df_final_with_dep_delay = df_final.join(\n",
    "#     df_dep_delay_only,\n",
    "#     on=join_keys,\n",
    "#     how='left'\n",
    "# )\n",
    "\n",
    "# print(f\"\\nFinal dataset with DEP_DELAY: {df_final_with_dep_delay.count()} rows, {len(df_final_with_dep_delay.columns)} columns\")\n",
    "# print(f\"Includes DEP_DELAY: {'DEP_DELAY' in df_final_with_dep_delay.columns}\")\n",
    "\n",
    "# # Check for any nulls in DEP_DELAY after join\n",
    "# null_count = df_final_with_dep_delay.filter(col('DEP_DELAY').isNull()).count()\n",
    "# print(f\"\\nNull values in DEP_DELAY after join: {null_count}\")\n",
    "\n",
    "# # Verify DEP_DELAY is continuous (not just 0/1)\n",
    "# print(\"\\nDEP_DELAY statistics (should show continuous values, not just 0/1):\")\n",
    "# df_final_with_dep_delay.select('DEP_DELAY').describe().show()\n",
    "\n",
    "# # Check distinct values to confirm it's not binary\n",
    "# distinct_values = df_final_with_dep_delay.select('DEP_DELAY').distinct().count()\n",
    "# print(f\"Number of distinct DEP_DELAY values: {distinct_values} (should be >> 2)\")\n",
    "\n",
    "# # Display sample to verify both DEP_DELAY and DEP_DEL15\n",
    "# print(\"\\nSample of data with both DEP_DELAY (continuous) and DEP_DEL15 (binary):\")\n",
    "# df_final_with_dep_delay.select(\n",
    "#     'FL_DATE', 'OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST', \n",
    "#     'DEP_DELAY', 'DEP_DEL15'\n",
    "# ).show(20)\n",
    "\n",
    "# # Verify the relationship: DEP_DEL15 should be 1 when DEP_DELAY >= 15, and 0 otherwise\n",
    "# print(\"\\nVerifying DEP_DELAY and DEP_DEL15 relationship:\")\n",
    "# relationship_check = df_final_with_dep_delay.groupBy('DEP_DEL15').agg(\n",
    "#     col('DEP_DEL15'),\n",
    "#     F.min('DEP_DELAY').alias('min_delay'),\n",
    "#     F.max('DEP_DELAY').alias('max_delay'),\n",
    "#     F.mean('DEP_DELAY').alias('avg_delay'),\n",
    "#     F.count('*').alias('count')\n",
    "# ).orderBy('DEP_DEL15')\n",
    "# relationship_check.show()\n",
    "\n",
    "# # Save the updated dataset\n",
    "# output_path = f\"{BASE_PATH}2015_final_feature_engineered_data_with_dep_delay\"\n",
    "# df_final_with_dep_delay.write.mode('overwrite').parquet(output_path)\n",
    "\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(f\"SUCCESS: Dataset with DEP_DELAY saved to: {output_path}\")\n",
    "# print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56dc85a6-c98b-4ca7-a24d-1a1a14d27414",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Convert CSV to Parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47de9b97-a002-4eb9-b883-b6c0533c7e49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"{data_BASE_DIR}/OTPW_3M/OTPW_3M/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e85403a6-e2b6-4da5-913d-d8f1f97c51f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_otpw_3m = (spark.read\n",
    "               .option(\"header\", \"true\")\n",
    "               .option(\"inferSchema\", \"true\")\n",
    "               .csv(\"dbfs:/mnt/mids-w261/OTPW_3M/OTPW_3M/OTPW_3M_2015.csv.gz\"))\n",
    "df_otpw_3m.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78aecc3c-ba3e-46f2-b6cc-6cc31b458d18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Save Parquet to Group Folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9a01450-3798-4eae-aabc-11eeb7bc98ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_otpw_3m.write.parquet(f\"{folder_path}/otpw_3m.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd699dec-dcee-4a41-94cb-544948c06c88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"{folder_path}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10b735f2-612e-432e-8f5a-e5b704628fe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Load Parquet from Group Folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc2ebdb6-dcf8-499f-a3a5-25de02b24fdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "otpw_3m = spark.read.parquet(f\"{folder_path}/otpw_3m.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92e15cb2-ee01-47cb-b05d-a7fa496a4862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Num rows: \", otpw_3m.count())\n",
    "print(\"Num cols: \", len(otpw_3m.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "880bbd5b-4f70-49b9-940d-4a7384fe49ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "otpw_3m.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9493c9e-f7aa-4aed-a020-4817873e9f19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83654956-f7a9-4739-ae97-27f646496170",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Comprehensive Type Casting (Data Type Standardization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "618ba7fc-fc7d-4acc-ad83-89e748e5d547",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== Standardizing Data Types ===\")\n",
    "integer_cols = [\n",
    "    \"QUARTER\", \"DAY_OF_MONTH\", \"DAY_OF_WEEK\",\n",
    "    \"DEP_DELAY_NEW\", \"DEP_DEL15\", \"DEP_DELAY_GROUP\",\n",
    "    \"TAXI_OUT\", \"WHEELS_OFF\", \"WHEELS_ON\", \"TAXI_IN\",\n",
    "    \"ARR_DELAY_NEW\", \"ARR_DEL15\", \"ARR_DELAY_GROUP\",\n",
    "    \"CANCELLED\", \"DIVERTED\",\n",
    "    \"FLIGHTS\", \"DISTANCE\", \"DISTANCE_GROUP\",\n",
    "    \"YEAR\", \"MONTH\",\n",
    "    \"OP_CARRIER_FL_NUM\", \"ORIGIN_AIRPORT_ID\", \"ORIGIN_AIRPORT_SEQ_ID\",\n",
    "    \"ORIGIN_CITY_MARKET_ID\", \"ORIGIN_STATE_FIPS\", \"ORIGIN_WAC\",\n",
    "    \"DEST_AIRPORT_ID\", \"DEST_AIRPORT_SEQ_ID\", \"DEST_CITY_MARKET_ID\",\n",
    "    \"DEST_STATE_FIPS\", \"DEST_WAC\", \"CRS_DEP_TIME\", \"CRS_ARR_TIME\",\n",
    "    \"HourlyPressureTendency\", \"Sunrise\", \"Sunset\"\n",
    "]\n",
    "\n",
    "float_cols = [\n",
    "    \"DEP_DELAY\", \"ARR_DELAY\",\n",
    "    \"CRS_ELAPSED_TIME\", \"ACTUAL_ELAPSED_TIME\", \"AIR_TIME\",\n",
    "    \"CARRIER_DELAY\", \"WEATHER_DELAY\", \"NAS_DELAY\", \"SECURITY_DELAY\", \"LATE_AIRCRAFT_DELAY\",\n",
    "    \"FIRST_DEP_TIME\", \"TOTAL_ADD_GTIME\", \"LONGEST_ADD_GTIME\",\n",
    "    \"origin_station_lat\", \"origin_station_lon\", \"origin_airport_lat\", \"origin_airport_lon\", \"origin_station_dis\",\n",
    "    \"dest_station_lat\", \"dest_station_lon\", \"dest_airport_lat\", \"dest_airport_lon\", \"dest_station_dis\",\n",
    "    \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\",\n",
    "    \"HourlyAltimeterSetting\", \"HourlyDewPointTemperature\", \"HourlyDryBulbTemperature\", \"HourlyPrecipitation\",\n",
    "    \"HourlyPressureChange\", \"HourlyRelativeHumidity\", \"HourlySeaLevelPressure\",\n",
    "    \"HourlyStationPressure\", \"HourlyVisibility\", \"HourlyWetBulbTemperature\", \"HourlyWindDirection\",\n",
    "    \"HourlyWindGustSpeed\", \"HourlyWindSpeed\",\n",
    "    \"DailyAverageDewPointTemperature\", \"DailyAverageDryBulbTemperature\", \"DailyAverageRelativeHumidity\",\n",
    "    \"DailyAverageSeaLevelPressure\", \"DailyAverageStationPressure\", \"DailyAverageWetBulbTemperature\",\n",
    "    \"DailyAverageWindSpeed\", \"DailyCoolingDegreeDays\", \"DailyDepartureFromNormalAverageTemperature\",\n",
    "    \"DailyHeatingDegreeDays\", \"DailyMaximumDryBulbTemperature\", \"DailyMinimumDryBulbTemperature\",\n",
    "    \"DailyPeakWindDirection\", \"DailyPeakWindSpeed\", \"DailyPrecipitation\", \"DailySnowDepth\", \"DailySnowfall\",\n",
    "    \"DailySustainedWindDirection\", \"DailySustainedWindSpeed\"\n",
    "]\n",
    "\n",
    "date_cols = [\n",
    "    \"FL_DATE\",\n",
    "    \"sched_depart_date_time\", \"sched_depart_date_time_UTC\",\n",
    "    \"four_hours_prior_depart_UTC\", \"two_hours_prior_depart_UTC\",\n",
    "    \"DATE\"\n",
    "]\n",
    "\n",
    "print(f\"Schema before casting:\")\n",
    "original_types = dict(otpw_3m.dtypes)\n",
    "\n",
    "# Cast columns according to type\n",
    "cast_counts = {\"integer\": 0, \"double\": 0, \"timestamp\": 0, \"unchanged\": 0}\n",
    "\n",
    "for c in otpw_3m.columns:\n",
    "    if c in integer_cols:\n",
    "        otpw_3m = otpw_3m.withColumn(c, col(c).cast(\"int\"))\n",
    "        cast_counts[\"integer\"] += 1\n",
    "    elif c in float_cols:\n",
    "        otpw_3m = otpw_3m.withColumn(c, col(c).cast(\"double\"))\n",
    "        cast_counts[\"double\"] += 1\n",
    "    elif c in date_cols:\n",
    "        otpw_3m = otpw_3m.withColumn(c, col(c).cast(\"timestamp\"))\n",
    "        cast_counts[\"timestamp\"] += 1\n",
    "    else:\n",
    "        cast_counts[\"unchanged\"] += 1\n",
    "\n",
    "print(f\"\\nType Casting Summary:\")\n",
    "print(f\"  Cast to integer: {cast_counts['integer']} columns\")\n",
    "print(f\"  Cast to double: {cast_counts['double']} columns\")\n",
    "print(f\"  Cast to timestamp: {cast_counts['timestamp']} columns\")\n",
    "print(f\"  Unchanged (strings, etc.): {cast_counts['unchanged']} columns\")\n",
    "\n",
    "print(f\"\\n Data types standardized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05513c71-fd32-46d6-8822-0d02fc500ff1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Dropping Rows Missing Important Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b54943-92a1-48f7-8523-b729434f2112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "required_cols = [\"DEP_DEL15\", \"FL_DATE\", \"CRS_DEP_TIME\", \"OP_CARRIER_FL_NUM\"] \n",
    "\n",
    "otpw_3m.select([\n",
    "    count(when(col(c).isNull(), c)).alias(f\"{c}_missing_vals\")\n",
    "    for c in required_cols\n",
    "]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b18a3f56-4246-40fb-b0cc-470dea01a90e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "otpw_3m_clean = otpw_3m.dropna(subset=required_cols)\n",
    "otpw_3m_clean.select([\n",
    "    count(when(col(c).isNull(), c)).alias(f\"{c}_missing_vals\")\n",
    "    for c in required_cols\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a7ab5fe-95b4-4010-8da6-a39cfc38b2a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Num rows: \", otpw_3m_clean.count())\n",
    "print(\"Num cols: \", len(otpw_3m_clean.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "181d8f66-3cb1-445b-b659-e19c81d4bc35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Drop Duplicate Rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50057db2-2924-469f-b01d-6e5f0dc86afd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dup_groups = otpw_3m_clean.groupBy(required_cols) \\\n",
    "               .agg(count(\"*\").alias(\"row_count\")) \\\n",
    "               .filter(\"row_count > 1\")\n",
    "print(\"Num of duplicate groups: \", dup_groups.count())\n",
    "dup_groups.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85ac748e-7fd2-4e9c-980b-e574153a98b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "before = otpw_3m_clean.count()\n",
    "otpw_3m_clean = otpw_3m_clean.dropDuplicates(subset=required_cols)\n",
    "after = otpw_3m_clean.count()\n",
    "print(f\"Dropped {before - after} duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7141a5c-3f76-4e01-8493-f30c55d38010",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Num rows: \", otpw_3m_clean.count())\n",
    "print(\"Num cols: \", len(otpw_3m_clean.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e801e5f9-a536-4dff-8324-3ab040af60f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Filter Out Canceled and Diverted Flights Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "873b4d21-be6e-42a0-982a-1971ce00c209",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "otpw_3m_clean = otpw_3m_clean.filter((col(\"CANCELLED\") != 1) | col(\"CANCELLED\").isNull())\n",
    "print(\"Num rows: \", otpw_3m_clean.count())\n",
    "print(\"Num cols: \", len(otpw_3m_clean.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17b5b6c8-9bd7-442f-b75e-e1986438c5b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop Diverted Flights:\n",
    "print(\"=== Dropping Diverted Flights ===\")\n",
    "before_count = otpw_3m_clean.count()\n",
    "otpw_3m_clean = otpw_3m_clean.filter((col(\"DIVERTED\") != 1) | col(\"DIVERTED\").isNull())\n",
    "after_count = otpw_3m_clean.count()\n",
    "diverted_dropped = before_count - after_count\n",
    "print(f\"Dropped {diverted_dropped:,} diverted flights ({diverted_dropped/before_count*100:.2f}%)\")\n",
    "print(f\"Remaining flights: {after_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "144b87f3-1246-4e67-aca5-c321889cd8ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Remove Columns with Insufficient or Unreliable Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec9c8d80-a276-4c90-be14-6590ffe0fccf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_rows = otpw_3m_clean.count()\n",
    "null_stats = []\n",
    "for c in otpw_3m_clean.columns:\n",
    "    null_count = otpw_3m_clean.filter(col(c).isNull()).count()\n",
    "    null_pct = null_count / total_rows\n",
    "    null_stats.append((c, null_count, null_pct))\n",
    "null_df = pd.DataFrame(null_stats, columns=[\"column\", \"null_count\", \"null_pct\"])\n",
    "null_df = null_df.sort_values(by=\"null_pct\", ascending=False)\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(null_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd6a8ca3-1f36-4db2-8ce7-268c7a0addf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null_threshold = 0.5\n",
    "important_sparse_cols_keep = [\n",
    "    \"SECURITY_DELAY\",\n",
    "    \"LATE_AIRCRAFT_DELAY\",\n",
    "    \"WEATHER_DELAY\",\n",
    "    \"CARRIER_DELAY\",\n",
    "    \"NAS_DELAY\",\n",
    "    \"HourlyWindGustSpeed\",\n",
    "    \"HourlyPresentWeatherType\",\n",
    "    \"HourlyPressureChange\",\n",
    "    \"HourlyPressureTendency\"\n",
    "]\n",
    "drop_cols = null_df[\n",
    "    (null_df[\"null_pct\"] > null_threshold) &\n",
    "    (~null_df[\"column\"].isin(important_sparse_cols_keep))\n",
    "][\"column\"].tolist()\n",
    "otpw_3m_filtered = otpw_3m_clean.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7468709d-f0b7-4d0e-b4d3-1a29fcdc9720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Num rows: \", otpw_3m_filtered.count())\n",
    "print(\"Num cols: \", len(otpw_3m_filtered.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9794dcde-7a4f-4c7a-ab96-80f47ac78d74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save checkpoint to group folder\n",
    "otpw_3m_filtered.write.parquet(f\"{folder_path}/otpw_3m_clean.parquet\")\n",
    "display(dbutils.fs.ls(f\"{folder_path}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d23e5a12-7481-46a2-90d2-7f738d9cf517",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Cast Certain Columns to Appropiate Data Types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c75371-05d9-412b-b236-99898e0162b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "otpw_3m_imputed = spark.read.parquet(f\"{folder_path}/otpw_3m_clean.parquet\")\n",
    "\n",
    "# Define columns that need type casting from string to numeric\n",
    "string_to_double_cols = [\n",
    "    # Hourly weather\n",
    "    \"HourlyAltimeterSetting\",\n",
    "    \"HourlyDewPointTemperature\",\n",
    "    \"HourlyDryBulbTemperature\",\n",
    "    \"HourlyPrecipitation\",\n",
    "    \"HourlyRelativeHumidity\",\n",
    "    \"HourlySeaLevelPressure\",\n",
    "    \"HourlyStationPressure\",\n",
    "    \"HourlyVisibility\",\n",
    "    \"HourlyWetBulbTemperature\",\n",
    "    \"HourlyWindDirection\",\n",
    "    \"HourlyWindGustSpeed\",\n",
    "    \"HourlyWindSpeed\",\n",
    "    # Daily weather\n",
    "    \"DailyAverageDryBulbTemperature\",\n",
    "    \"DailyMinimumDryBulbTemperature\",\n",
    "    \"DailyCoolingDegreeDays\",\n",
    "    \"DailyDepartureFromNormalAverageTemperature\",\n",
    "    \"DailyHeatingDegreeDays\",\n",
    "    \"DailyPeakWindDirection\",\n",
    "    \"DailyPeakWindSpeed\",\n",
    "    \"DailyPrecipitation\",\n",
    "    \"DailySnowDepth\",\n",
    "    \"DailySnowfall\",\n",
    "    \"DailySustainedWindDirection\",\n",
    "    \"DailySustainedWindSpeed\",\n",
    "    # Normals\n",
    "    \"AWND\", \"CDSD\", \"CLDD\", \"DSNW\", \"HDSD\", \"HTDD\",\n",
    "    \"NormalsCoolingDegreeDay\",\n",
    "    \"NormalsHeatingDegreeDay\"\n",
    "]\n",
    "\n",
    "# Add all Monthly columns (they're all strings that should be numeric)\n",
    "monthly_cols = [col for col in otpw_3m_imputed.columns if col.startswith(\"Monthly\")]\n",
    "string_to_double_cols.extend(monthly_cols)\n",
    "\n",
    "# Add all ShortDurationPrecipitationValue columns\n",
    "short_duration_cols = [col for col in otpw_3m_imputed.columns if \"ShortDurationPrecipitationValue\" in col]\n",
    "string_to_double_cols.extend(short_duration_cols)\n",
    "\n",
    "# Remove duplicates\n",
    "string_to_double_cols = list(set(string_to_double_cols))\n",
    "\n",
    "# Cast string columns to double (will convert non-numeric values to null)\n",
    "print(\"=== Converting String Columns to Numeric ===\")\n",
    "cast_count = 0\n",
    "for col_name in string_to_double_cols:\n",
    "    if col_name in otpw_3m_imputed.columns:\n",
    "        otpw_3m_imputed = otpw_3m_imputed.withColumn(\n",
    "            col_name,\n",
    "            col(col_name).cast(DoubleType())\n",
    "        )\n",
    "        cast_count += 1\n",
    "        print(f\"Converted {col_name} to DoubleType\")\n",
    "\n",
    "print(f\"\\nTotal columns converted: {cast_count}\")\n",
    "display(otpw_3m_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a5d34e9-b736-433b-a191-3d1e7dae90bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Impute Null Variables with Median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8730808-fb1d-4668-9465-e52279603ca3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "2": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"name\":207},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762035889881}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 2
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Impute Null Variables with Tailored Strategy:\n",
    "\n",
    "# Define variable types for imputation\n",
    "continuous_cols = [\n",
    "    \"CRS_ELAPSED_TIME\", \"TAXI_OUT\", \"TAXI_IN\", \"WHEELS_OFF\", \"WHEELS_ON\",\n",
    "    \"DISTANCE\", \"CRS_DEP_TIME\", \"CRS_ARR_TIME\",\n",
    "    \"HourlyAltimeterSetting\", \"HourlyPrecipitation\", \"HourlyVisibility\", \n",
    "    \"HourlyWindSpeed\", \"HourlyWindGustSpeed\", \"HourlyWindDirection\",\n",
    "    \"HourlyDryBulbTemperature\", \"HourlyDewPointTemperature\", \"HourlyWetBulbTemperature\",\n",
    "    \"HourlyRelativeHumidity\", \"HourlySeaLevelPressure\", \"HourlyStationPressure\"\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    \"ORIGIN\", \"DEST\", \"OP_UNIQUE_CARRIER\", \"TAIL_NUM\", \n",
    "    \"ORIGIN_AIRPORT_SEQ_ID\", \"DEST_AIRPORT_SEQ_ID\",\n",
    "    \"ORIGIN_CITY_MARKET_ID\", \"DEST_CITY_MARKET_ID\",\n",
    "    \"ORIGIN_CITY_NAME\", \"DEST_CITY_NAME\", \"ORIGIN_STATE_ABR\", \"DEST_STATE_ABR\",\n",
    "    \"HourlyPresentWeatherType\", \"CANCELLATION_CODE\"\n",
    "]\n",
    "\n",
    "boolean_cols = [\n",
    "    # Add boolean columns if they exist in your dataset\n",
    "    # \"IS_WEEKEND\"\n",
    "]\n",
    "\n",
    "# 1. Cast continuous columns to DoubleType if needed\n",
    "print(\"=== Casting Non-Numeric Continuous Columns ===\")\n",
    "for col_name in continuous_cols:\n",
    "    if col_name in otpw_3m_imputed.columns:\n",
    "        col_type = dict(otpw_3m_imputed.dtypes)[col_name]\n",
    "        if col_type not in [\"double\", \"float\", \"int\", \"bigint\", \"integer\"]:\n",
    "            otpw_3m_imputed = otpw_3m_imputed.withColumn(\n",
    "                col_name,\n",
    "                col(col_name).cast(DoubleType())\n",
    "            )\n",
    "            print(f\"Cast {col_name} from {col_type} to DoubleType\")\n",
    "\n",
    "# 2. Impute continuous variables with median\n",
    "print(\"\\n=== Imputing Continuous Variables with Median ===\")\n",
    "impute_values = {}\n",
    "for col_name in continuous_cols:\n",
    "    if col_name in otpw_3m_imputed.columns:\n",
    "        try:\n",
    "            median_value = otpw_3m_imputed.select(col_name).na.drop().approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "            if median_value is not None:\n",
    "                impute_values[col_name] = median_value\n",
    "                null_count = otpw_3m_imputed.filter(col(col_name).isNull()).count()\n",
    "                print(f\"{col_name}: median = {median_value:.2f}, imputing {null_count} nulls\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not impute {col_name}: {e}\")\n",
    "\n",
    "otpw_3m_imputed = otpw_3m_imputed.fillna(impute_values)\n",
    "\n",
    "# 2. CATEGORICAL VARIABLES: Impute with \"UNK\" (Unknown)\n",
    "print(\"\\n=== Imputing Categorical Variables with 'UNK' ===\")\n",
    "for col_name in categorical_cols:\n",
    "    if col_name in otpw_3m_imputed.columns:\n",
    "        col_type = dict(otpw_3m_imputed.dtypes)[col_name]\n",
    "        \n",
    "        # Cast integer categorical columns to string first\n",
    "        if col_type in [\"int\", \"bigint\", \"integer\"]:\n",
    "            print(f\"Converting {col_name} from {col_type} to StringType for UNK imputation\")\n",
    "            otpw_3m_imputed = otpw_3m_imputed.withColumn(\n",
    "                col_name,\n",
    "                col(col_name).cast(\"string\")\n",
    "            )\n",
    "        \n",
    "        null_count = otpw_3m_imputed.filter(col(col_name).isNull()).count()\n",
    "        if null_count > 0:\n",
    "            otpw_3m_imputed = otpw_3m_imputed.withColumn(\n",
    "                col_name,\n",
    "                when(col(col_name).isNull(), lit(\"UNK\")).otherwise(col(col_name))\n",
    "            )\n",
    "            print(f\"{col_name}: {null_count} nulls replaced with 'UNK'\")\n",
    "\n",
    "# 3. BOOLEAN VARIABLES: Impute with majority class\n",
    "if boolean_cols:\n",
    "    print(\"\\n=== Imputing Boolean Variables with Majority Class ===\")\n",
    "    for col_name in boolean_cols:\n",
    "        if col_name in otpw_3m_imputed.columns:\n",
    "            mode_row = (\n",
    "                otpw_3m_imputed.groupBy(col_name)\n",
    "                .agg(count(\"*\").alias(\"count\"))\n",
    "                .orderBy(desc(\"count\"))\n",
    "                .filter(col(col_name).isNotNull())\n",
    "                .first()\n",
    "            )\n",
    "            if mode_row:\n",
    "                mode_value = mode_row[0]\n",
    "                null_count = otpw_3m_imputed.filter(col(col_name).isNull()).count()\n",
    "                if null_count > 0:  # Only impute if there are nulls\n",
    "                    otpw_3m_imputed = otpw_3m_imputed.withColumn(\n",
    "                        col_name,\n",
    "                        when(col(col_name).isNull(), lit(mode_value)).otherwise(col(col_name))\n",
    "                    )\n",
    "                    print(f\"{col_name}: {null_count} nulls replaced with majority class '{mode_value}'\")\n",
    "            else:\n",
    "                print(f\"Warning: Could not determine mode for {col_name}\")\n",
    "\n",
    "# Display imputed data\n",
    "display(otpw_3m_imputed)\n",
    "\n",
    "# Check remaining nulls\n",
    "print(\"\\n=== Remaining Null Values ===\")\n",
    "total_rows = otpw_3m_imputed.count()\n",
    "null_stats = []\n",
    "for c in otpw_3m_imputed.columns:\n",
    "    null_count = otpw_3m_imputed.filter(col(c).isNull()).count()\n",
    "    null_pct = null_count / total_rows\n",
    "    if null_count > 0:  # Only show columns with remaining nulls\n",
    "        null_stats.append((c, null_count, null_pct))\n",
    "\n",
    "if null_stats:\n",
    "    null_df = pd.DataFrame(null_stats, columns=[\"column\", \"null_count\", \"null_pct\"])\n",
    "    null_df = null_df.sort_values(by=\"null_pct\", ascending=False)\n",
    "    display(null_df)\n",
    "else:\n",
    "    print(\" No remaining null values!\")\n",
    "\n",
    "print(f\"\\nFinal dataset shape:\")\n",
    "print(f\"Num rows: {otpw_3m_imputed.count()}\")\n",
    "print(f\"Num cols: {len(otpw_3m_imputed.columns)}\")\n",
    "\n",
    "# Save checkpoint to group folder\n",
    "otpw_3m_imputed.write.mode(\"overwrite\").parquet(f\"{folder_path}/otpw_3m_imputed.parquet\")\n",
    "print(f\"\\n Saved to: {folder_path}/otpw_3m_imputed.parquet\")\n",
    "display(dbutils.fs.ls(f\"{folder_path}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b66daed5-8b4a-4060-b7cf-e35f3c255227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_rows = otpw_3m_imputed.count()\n",
    "null_stats = []\n",
    "for c in otpw_3m_imputed.columns:\n",
    "    null_count = otpw_3m_imputed.filter(col(c).isNull()).count()\n",
    "    null_pct = null_count / total_rows\n",
    "    null_stats.append((c, null_count, null_pct))\n",
    "null_df = pd.DataFrame(null_stats, columns=[\"column\", \"null_count\", \"null_pct\"])\n",
    "null_df = null_df.sort_values(by=\"null_pct\", ascending=False)\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(null_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d22add3-8f82-4373-a291-a0db9105c373",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Num rows: \", otpw_3m_imputed.count())\n",
    "print(\"Num cols: \", len(otpw_3m_imputed.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24bce82b-2a85-4e7e-af57-9a553b18f75c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Convert Target Variable to Binary Integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8085bbd9-cc6e-452a-8d6f-31ee422679ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== Converting Target Variable DEP_DEL15 to Binary Integer ===\")\n",
    "\n",
    "# Check current type and distribution\n",
    "print(f\"Current DEP_DEL15 type: {dict(otpw_3m_imputed.dtypes)['DEP_DEL15']}\")\n",
    "print(\"\\nDEP_DEL15 value distribution:\")\n",
    "otpw_3m_imputed.groupBy(\"DEP_DEL15\").count().orderBy(\"DEP_DEL15\").show()\n",
    "\n",
    "# Convert to integer (0 or 1) for binary classification\n",
    "otpw_3m_imputed = otpw_3m_imputed.withColumn(\n",
    "    \"DEP_DEL15\",\n",
    "    col(\"DEP_DEL15\").cast(IntegerType())\n",
    ")\n",
    "\n",
    "print(f\"\\nNew DEP_DEL15 type: {dict(otpw_3m_imputed.dtypes)['DEP_DEL15']}\")\n",
    "print(\"\\nConfirming binary values:\")\n",
    "otpw_3m_imputed.groupBy(\"DEP_DEL15\").count().orderBy(\"DEP_DEL15\").show()\n",
    "\n",
    "# Also convert ARR_DEL15 if it's a target for arrival delay prediction\n",
    "if \"ARR_DEL15\" in otpw_3m_imputed.columns:\n",
    "    print(\"\\n=== Converting ARR_DEL15 to Binary Integer ===\")\n",
    "    otpw_3m_imputed = otpw_3m_imputed.withColumn(\n",
    "        \"ARR_DEL15\",\n",
    "        col(\"ARR_DEL15\").cast(IntegerType())\n",
    "    )\n",
    "    print(f\"New ARR_DEL15 type: {dict(otpw_3m_imputed.dtypes)['ARR_DEL15']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e89995f7-0595-4369-a1d6-f2b93c88a601",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Remove All Leakage Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d841969b-562f-4fe1-9001-c39f6ca489b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== Removing Data Leakage Features ===\")\n",
    "\n",
    "# Define all leakage features (features known only after flight completion)\n",
    "leakage_features = [\n",
    "    # Actual times (only known after flight)\n",
    "    \"DEP_TIME\", \"ARR_TIME\", \"WHEELS_OFF\", \"WHEELS_ON\",\n",
    "    \n",
    "    # Actual delays (target-related)\n",
    "    \"DEP_DELAY\", \"DEP_DELAY_NEW\", \"DEP_DELAY_GROUP\",\n",
    "    \"ARR_DELAY\", \"ARR_DELAY_NEW\", \"ARR_DELAY_GROUP\",\n",
    "    \n",
    "    # Taxi times (only known after flight)\n",
    "    \"TAXI_OUT\", \"TAXI_IN\",\n",
    "    \n",
    "    # Flight durations (only known after completion)\n",
    "    \"ACTUAL_ELAPSED_TIME\", \"AIR_TIME\",\n",
    "    \n",
    "    # Delay breakdowns (only known after delay occurs)\n",
    "    \"CARRIER_DELAY\", \"WEATHER_DELAY\", \"NAS_DELAY\", \n",
    "    \"SECURITY_DELAY\", \"LATE_AIRCRAFT_DELAY\",\n",
    "    \n",
    "    # Other post-flight info\n",
    "    \"FIRST_DEP_TIME\", \"TOTAL_ADD_GTIME\", \"LONGEST_ADD_GTIME\",\n",
    "    \n",
    "    # Keep ARR_DEL15 if predicting departure delay, remove if predicting arrival\n",
    "    \"ARR_DEL15\"  # Remove this since we're predicting DEP_DEL15\n",
    "]\n",
    "\n",
    "# Count and remove leakage features\n",
    "existing_leakage = [col for col in leakage_features if col in otpw_3m_imputed.columns]\n",
    "print(f\"Found {len(existing_leakage)} leakage features to remove:\")\n",
    "for feat in existing_leakage:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "otpw_3m_clean_no_leakage = otpw_3m_imputed.drop(*existing_leakage)\n",
    "\n",
    "print(f\"\\nColumns before: {len(otpw_3m_imputed.columns)}\")\n",
    "print(f\"Columns after: {len(otpw_3m_clean_no_leakage.columns)}\")\n",
    "print(f\"Removed: {len(otpw_3m_imputed.columns) - len(otpw_3m_clean_no_leakage.columns)} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "115ce74a-e793-452e-bf82-18814956de24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create Comprehensive Column Classification Table (Appendix B):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e507d0f5-ab89-40a3-99a1-d7ef5672b0d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define column categories based on functional type\n",
    "column_classification = {\n",
    "    # Target Variables\n",
    "    \"DEP_DEL15\": {\"functional_type\": \"Binary Target\", \"data_type\": \"integer\", \"description\": \"Departure delay 15 minutes (0/1)\"},\n",
    "    \"ARR_DEL15\": {\"functional_type\": \"Binary Target\", \"data_type\": \"integer\", \"description\": \"Arrival delay 15 minutes (0/1)\"},\n",
    "    \n",
    "    # Temporal Features\n",
    "    \"YEAR\": {\"functional_type\": \"Categorical (Ordinal)\", \"data_type\": \"integer\", \"description\": \"Year of flight\"},\n",
    "    \"QUARTER\": {\"functional_type\": \"Categorical (Ordinal)\", \"data_type\": \"integer\", \"description\": \"Quarter (1-4)\"},\n",
    "    \"MONTH\": {\"functional_type\": \"Categorical (Ordinal)\", \"data_type\": \"integer\", \"description\": \"Month (1-12)\"},\n",
    "    \"DAY_OF_MONTH\": {\"functional_type\": \"Categorical (Ordinal)\", \"data_type\": \"integer\", \"description\": \"Day of month (1-31)\"},\n",
    "    \"DAY_OF_WEEK\": {\"functional_type\": \"Categorical (Ordinal)\", \"data_type\": \"integer\", \"description\": \"Day of week (1-7)\"},\n",
    "    \"FL_DATE\": {\"functional_type\": \"Temporal\", \"data_type\": \"date\", \"description\": \"Flight date\"},\n",
    "    \n",
    "    # Flight Identifiers\n",
    "    \"OP_UNIQUE_CARRIER\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Unique carrier code\"},\n",
    "    \"OP_CARRIER_AIRLINE_ID\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"integer\", \"description\": \"Airline ID\"},\n",
    "    \"OP_CARRIER\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Carrier code\"},\n",
    "    \"TAIL_NUM\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Tail number\"},\n",
    "    \"OP_CARRIER_FL_NUM\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"integer\", \"description\": \"Flight number\"},\n",
    "    \n",
    "    # Origin Airport Features\n",
    "    \"ORIGIN_AIRPORT_ID\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"integer\", \"description\": \"Origin airport ID\"},\n",
    "    \"ORIGIN_AIRPORT_SEQ_ID\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Origin airport sequence ID\"},\n",
    "    \"ORIGIN_CITY_MARKET_ID\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Origin city market ID\"},\n",
    "    \"ORIGIN\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Origin airport code\"},\n",
    "    \"ORIGIN_CITY_NAME\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Origin city name\"},\n",
    "    \"ORIGIN_STATE_ABR\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Origin state abbreviation\"},\n",
    "    \"ORIGIN_STATE_FIPS\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"integer\", \"description\": \"Origin state FIPS code\"},\n",
    "    \"ORIGIN_STATE_NM\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Origin state name\"},\n",
    "    \"ORIGIN_WAC\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"integer\", \"description\": \"Origin World Area Code\"},\n",
    "    \n",
    "    # Destination Airport Features\n",
    "    \"DEST_AIRPORT_ID\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"integer\", \"description\": \"Destination airport ID\"},\n",
    "    \"DEST_AIRPORT_SEQ_ID\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Destination airport sequence ID\"},\n",
    "    \"DEST_CITY_MARKET_ID\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Destination city market ID\"},\n",
    "    \"DEST\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Destination airport code\"},\n",
    "    \"DEST_CITY_NAME\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Destination city name\"},\n",
    "    \"DEST_STATE_ABR\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Destination state abbreviation\"},\n",
    "    \"DEST_STATE_FIPS\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"integer\", \"description\": \"Destination state FIPS code\"},\n",
    "    \"DEST_STATE_NM\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Destination state name\"},\n",
    "    \"DEST_WAC\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"integer\", \"description\": \"Destination World Area Code\"},\n",
    "    \n",
    "    # Timing Features\n",
    "    \"CRS_DEP_TIME\": {\"functional_type\": \"Continuous (Cyclic)\", \"data_type\": \"integer\", \"description\": \"Scheduled departure time (HHMM)\"},\n",
    "    \"CRS_ARR_TIME\": {\"functional_type\": \"Continuous (Cyclic)\", \"data_type\": \"integer\", \"description\": \"Scheduled arrival time (HHMM)\"},\n",
    "    \"DEP_TIME\": {\"functional_type\": \"Continuous (Cyclic)\", \"data_type\": \"integer\", \"description\": \"Actual departure time (HHMM) - LEAKAGE\"},\n",
    "    \"ARR_TIME\": {\"functional_type\": \"Continuous (Cyclic)\", \"data_type\": \"integer\", \"description\": \"Actual arrival time (HHMM) - LEAKAGE\"},\n",
    "    \"DEP_TIME_BLK\": {\"functional_type\": \"Categorical (Ordinal)\", \"data_type\": \"string\", \"description\": \"Departure time block\"},\n",
    "    \"ARR_TIME_BLK\": {\"functional_type\": \"Categorical (Ordinal)\", \"data_type\": \"string\", \"description\": \"Arrival time block\"},\n",
    "    \n",
    "    # Flight Performance - LEAKAGE FEATURES\n",
    "    \"DEP_DELAY\": {\"functional_type\": \"Continuous - LEAKAGE\", \"data_type\": \"double\", \"description\": \"Departure delay in minutes\"},\n",
    "    \"DEP_DELAY_NEW\": {\"functional_type\": \"Continuous - LEAKAGE\", \"data_type\": \"double\", \"description\": \"Departure delay (new calculation)\"},\n",
    "    \"DEP_DELAY_GROUP\": {\"functional_type\": \"Categorical - LEAKAGE\", \"data_type\": \"integer\", \"description\": \"Departure delay group\"},\n",
    "    \"ARR_DELAY\": {\"functional_type\": \"Continuous - LEAKAGE\", \"data_type\": \"double\", \"description\": \"Arrival delay in minutes\"},\n",
    "    \"ARR_DELAY_NEW\": {\"functional_type\": \"Continuous - LEAKAGE\", \"data_type\": \"double\", \"description\": \"Arrival delay (new calculation)\"},\n",
    "    \"ARR_DELAY_GROUP\": {\"functional_type\": \"Categorical - LEAKAGE\", \"data_type\": \"integer\", \"description\": \"Arrival delay group\"},\n",
    "    \"TAXI_OUT\": {\"functional_type\": \"Continuous - LEAKAGE\", \"data_type\": \"double\", \"description\": \"Taxi out time in minutes\"},\n",
    "    \"TAXI_IN\": {\"functional_type\": \"Continuous - LEAKAGE\", \"data_type\": \"double\", \"description\": \"Taxi in time in minutes\"},\n",
    "    \"WHEELS_OFF\": {\"functional_type\": \"Continuous - LEAKAGE\", \"data_type\": \"integer\", \"description\": \"Wheels off time (HHMM)\"},\n",
    "    \"WHEELS_ON\": {\"functional_type\": \"Continuous - LEAKAGE\", \"data_type\": \"integer\", \"description\": \"Wheels on time (HHMM)\"},\n",
    "    \"ACTUAL_ELAPSED_TIME\": {\"functional_type\": \"Continuous - LEAKAGE\", \"data_type\": \"double\", \"description\": \"Actual elapsed time\"},\n",
    "    \"AIR_TIME\": {\"functional_type\": \"Continuous - LEAKAGE\", \"data_type\": \"double\", \"description\": \"Air time in minutes\"},\n",
    "    \n",
    "    # Flight Distance\n",
    "    \"CRS_ELAPSED_TIME\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Scheduled elapsed time\"},\n",
    "    \"DISTANCE\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Flight distance in miles\"},\n",
    "    \"DISTANCE_GROUP\": {\"functional_type\": \"Categorical (Ordinal)\", \"data_type\": \"integer\", \"description\": \"Distance group\"},\n",
    "    \n",
    "    # Cancellation/Diversion\n",
    "    \"CANCELLED\": {\"functional_type\": \"Binary\", \"data_type\": \"double\", \"description\": \"Cancelled indicator (0/1)\"},\n",
    "    \"CANCELLATION_CODE\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Cancellation reason code\"},\n",
    "    \"DIVERTED\": {\"functional_type\": \"Binary\", \"data_type\": \"double\", \"description\": \"Diverted indicator (0/1)\"},\n",
    "    \n",
    "    # Delay Breakdown - SPARSE/LEAKAGE\n",
    "    \"CARRIER_DELAY\": {\"functional_type\": \"Continuous - SPARSE/LEAKAGE\", \"data_type\": \"double\", \"description\": \"Carrier delay in minutes\"},\n",
    "    \"WEATHER_DELAY\": {\"functional_type\": \"Continuous - SPARSE/LEAKAGE\", \"data_type\": \"double\", \"description\": \"Weather delay in minutes\"},\n",
    "    \"NAS_DELAY\": {\"functional_type\": \"Continuous - SPARSE/LEAKAGE\", \"data_type\": \"double\", \"description\": \"NAS delay in minutes\"},\n",
    "    \"SECURITY_DELAY\": {\"functional_type\": \"Continuous - SPARSE/LEAKAGE\", \"data_type\": \"double\", \"description\": \"Security delay in minutes\"},\n",
    "    \"LATE_AIRCRAFT_DELAY\": {\"functional_type\": \"Continuous - SPARSE/LEAKAGE\", \"data_type\": \"double\", \"description\": \"Late aircraft delay in minutes\"},\n",
    "    \n",
    "    # Hourly Weather Features (Origin)\n",
    "    \"HourlyAltimeterSetting\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Altimeter setting (converted from string)\"},\n",
    "    \"HourlyDewPointTemperature\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Dew point temperature (converted from string)\"},\n",
    "    \"HourlyDryBulbTemperature\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Dry bulb temperature (converted from string)\"},\n",
    "    \"HourlyPrecipitation\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Precipitation amount (converted from string)\"},\n",
    "    \"HourlyRelativeHumidity\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Relative humidity (converted from string)\"},\n",
    "    \"HourlySeaLevelPressure\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Sea level pressure (converted from string)\"},\n",
    "    \"HourlyStationPressure\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Station pressure (converted from string)\"},\n",
    "    \"HourlyVisibility\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Visibility (converted from string)\"},\n",
    "    \"HourlyWetBulbTemperature\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Wet bulb temperature (converted from string)\"},\n",
    "    \"HourlyWindDirection\": {\"functional_type\": \"Continuous (Cyclic)\", \"data_type\": \"double\", \"description\": \"Wind direction in degrees (converted from string)\"},\n",
    "    \"HourlyWindGustSpeed\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Wind gust speed (converted from string)\"},\n",
    "    \"HourlyWindSpeed\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Wind speed (converted from string)\"},\n",
    "    \"HourlyPresentWeatherType\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Weather condition codes\"},\n",
    "    \"HourlyPressureChange\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Pressure change\"},\n",
    "    \"HourlyPressureTendency\": {\"functional_type\": \"Categorical (Ordinal)\", \"data_type\": \"integer\", \"description\": \"Pressure tendency code\"},\n",
    "    \n",
    "    # Location Features\n",
    "    \"origin_station_lat\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Origin station latitude\"},\n",
    "    \"origin_station_lon\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Origin station longitude\"},\n",
    "    \"origin_airport_lat\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Origin airport latitude\"},\n",
    "    \"origin_airport_lon\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Origin airport longitude\"},\n",
    "    \"dest_station_lat\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Destination station latitude\"},\n",
    "    \"dest_station_lon\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Destination station longitude\"},\n",
    "    \"dest_airport_lat\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Destination airport latitude\"},\n",
    "    \"dest_airport_lon\": {\"functional_type\": \"Continuous\", \"data_type\": \"double\", \"description\": \"Destination airport longitude\"},\n",
    "    \n",
    "    # Text/Metadata\n",
    "    \"NAME\": {\"functional_type\": \"Text/Metadata\", \"data_type\": \"string\", \"description\": \"Weather station name\"},\n",
    "    \"REPORT_TYPE\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Weather report type\"},\n",
    "    \"SOURCE\": {\"functional_type\": \"Categorical (Nominal)\", \"data_type\": \"string\", \"description\": \"Weather data source\"},\n",
    "    \"HourlySkyConditions\": {\"functional_type\": \"Text\", \"data_type\": \"string\", \"description\": \"Sky conditions description\"},\n",
    "    \"REM\": {\"functional_type\": \"Text\", \"data_type\": \"string\", \"description\": \"Remarks/comments\"},\n",
    "}\n",
    "\n",
    "# Get actual columns from dataset\n",
    "actual_columns = otpw_3m_imputed.columns\n",
    "actual_dtypes = dict(otpw_3m_imputed.dtypes)\n",
    "\n",
    "# Create comprehensive table\n",
    "appendix_b_data = []\n",
    "for col in actual_columns:\n",
    "    if col in column_classification:\n",
    "        info = column_classification[col]\n",
    "        appendix_b_data.append({\n",
    "            \"Column Name\": col,\n",
    "            \"Functional Type\": info[\"functional_type\"],\n",
    "            \"Current Data Type\": actual_dtypes[col],\n",
    "            \"Expected Data Type\": info[\"data_type\"],\n",
    "            \"Description\": info[\"description\"]\n",
    "        })\n",
    "    else:\n",
    "        # For columns not explicitly classified\n",
    "        appendix_b_data.append({\n",
    "            \"Column Name\": col,\n",
    "            \"Functional Type\": \"Unclassified\",\n",
    "            \"Current Data Type\": actual_dtypes[col],\n",
    "            \"Expected Data Type\": actual_dtypes[col],\n",
    "            \"Description\": \"Not yet classified\"\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "appendix_b = pd.DataFrame(appendix_b_data)\n",
    "\n",
    "# Display the table\n",
    "print(\"=\" * 100)\n",
    "print(\"APPENDIX B: Comprehensive Column Classification and Type Information\")\n",
    "print(\"=\" * 100)\n",
    "display(appendix_b)\n",
    "\n",
    "# Save to CSV for documentation\n",
    "appendix_b.to_csv(f\"{folder_path.replace('dbfs:', '/dbfs')}/appendix_b_column_classification.csv\", index=False)\n",
    "print(f\"\\n Saved Appendix B to: {folder_path}/appendix_b_column_classification.csv\")\n",
    "\n",
    "# Summary statistics by functional type\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Summary by Functional Type:\")\n",
    "print(\"=\" * 100)\n",
    "summary = appendix_b.groupby(\"Functional Type\").size().reset_index(name=\"Count\")\n",
    "summary = summary.sort_values(\"Count\", ascending=False)\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "378a0978-2188-46ba-899d-7ed51057db9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save checkpoint to group folder\n",
    "otpw_3m_imputed.write.parquet(f\"{folder_path}/otpw_3m_imputed.parquet\")\n",
    "display(dbutils.fs.ls(f\"{folder_path}\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Team_4_4_Data_Cleaning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}